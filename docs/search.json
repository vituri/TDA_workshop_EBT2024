[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TDA Workshop - EBT 2024",
    "section": "",
    "text": "Welcome!\nThis digital book and the corresponding repository will hold all materials necessary to the Topological Data Analysis workshop, presented at the Encontro Brasileiro de Topologia (Brazilian Topology Meeting) in July 2024.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "3d-shapes.html",
    "href": "3d-shapes.html",
    "title": "3  3d shape classification",
    "section": "",
    "text": "3.1 The dataset\nTo get in touch with the classics, we are going to use the 3d shape dataset seen in (Singh et al. 2007).\nThe dataset can be found at http://people.csail.mit.edu/sumner/research/deftransfer/data.html. It consists of some reference pose of animals and human faces. The files used in this lesson can be found in this Google drive. After downloading it, unzip the file and put then inside a directory called “meshes”.\nThe files are written in the “.obj” format. They are meshes: sets of points and triangles that form a 3d image like the ones we can see in videogames.\nLet’s start with a flamingo shape. We load some libraries\n# read meshes and plot\nusing Meshes, GeoIO\nimport CairoMakie as gl\n\n# see progress\nusing ProgressMeter\n\n# dataframes\nusing DataFramesMeta, CSV, Chain\n\n# metric spaces and graphs\nusing MetricSpaces\nusing Graphs, SimpleWeightedGraphs\n\n# persistent homology\nimport Ripserer\nimport PersistenceDiagrams as Pd\nimport Plots\n\n# comparing the distance matrix\nusing Clustering, StatsPlots\nimport StatisticalMeasures.ConfusionMatrices as CM\nusing MultivariateStats\nand define functions to read and visualize shapes\nCode\nfunction list_files(path=\"\", pattern=\"\")\n    files =\n        @chain begin\n            map(walkdir(path)) do (root, dirs, files)\n                joinpath.(root, files)\n            end\n            reduce(vcat, _)\n            filter(x -&gt; occursin(pattern, x), _)\n        end\n\n    files\nend;\n\nfunction get_class_files(class)\n    @chain begin list_files(\"meshes/\", class)\n        filter(x -&gt; occursin(\".obj\", x), _)\n    end\nend;\n\nget_class_from_file(x) = split(x, \"-\")[1]\n\nread_mesh(filepath) = GeoIO.load(filepath).geometry;\n\nplot_mesh(ms) = viz(ms, showfacets = true, alpha = 0.5);\nThe reference pose is the following:\nfilepath = \"meshes/flamingo-poses/flam-reference.obj\"\nms = read_mesh(filepath)\nplot_mesh(ms)\nWe can also visualize it as a gif\n# fig, ax, plt = plot_mesh(ms);\n\n# gl.record(fig, \"images/3d-shapes/flamingo-ref.gif\", 0:31) do i\n#     gl.rotate!(fig.scene, Vec3f(0, 0, 1), i * pi/16)\n# end;\nand see its details:",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#loading-some-libraries",
    "href": "3d-shapes.html#loading-some-libraries",
    "title": "2  3d shape classification using persistent homology",
    "section": "3.1 Loading some libraries",
    "text": "3.1 Loading some libraries\n\nusing Meshes, GeoIO\nimport GLMakie as gl\nimport DelimitedFiles\nusing ProgressMeter\n\nusing Graphs, SimpleWeightedGraphs\nusing MetricSpaces, Ripserer, PersistenceDiagrams\nusing Chain\n\n\n# functions\nfunction reduz_obj(arquivo, n_points=1000)\n    geotable = GeoIO.load(arquivo)\n\n    X_total = geotable.vertices .|&gt; coordinates .|&gt; Vector |&gt; EuclideanSpace\n\n    ids = farthest_points_sample(X_total, n_points)\n    X = X_total[ids]\n\n    arquivo_novo = replace(arquivo, \".obj\" =&gt; \".csv\")\n    DelimitedFiles.writedlm(arquivo_novo, stack(X)' |&gt; Matrix, \",\")\n\n    X\nend\n\nfunction meshes_to_csv(dir_path)\n    for (root, dirs, files) ∈ collect(walkdir(dir_path))\n        for file ∈ files\n            if occursin(\".obj\", file)\n                arquivo = joinpath(root, file)\n                println(arquivo)\n                reduz_obj(arquivo)\n            end\n        end\n    end\nend\n\nread_mesh(arquivo) = GeoIO.load(arquivo).geometry\n\nfunction mesh_to_graph(ms, X)\n    g = SimpleWeightedGraph()\n    n = length(X)\n    add_vertices!(g, n)\n\n    triangles = ms.topology.connec\n\n    @showprogress desc = \"Adding vertices to graph...\" for t ∈ triangles\n        v1, v2, v3 = t.indices\n        add_edge!(g, v1, v2, dist_euclidean(X[v1], X[v2]))\n\n        add_edge!(g, v1, v3, dist_euclidean(X[v1], X[v3]))\n\n        add_edge!(g, v2, v3, dist_euclidean(X[v2], X[v3]))\n    end\n\n    g\nend\n\nmesh_to_metric_space(ms) = ms.vertices .|&gt; coordinates .|&gt; Vector |&gt; EuclideanSpace\n\nfunction geodesic_distance_from_graph(g, ids)\n    n = length(ids)\n    D = zeros(n, n)\n\n    @showprogress desc = \"Calculating geodesic distance...\" Threads.@threads for (i, id) ∈ collect(enumerate(ids))\n        dts = dijkstra_shortest_paths(g, id)\n        D[i, :] = dts.dists[ids]\n    end\n\n    return D\nend\n\nplot_mesh(ms) = viz(ms);\n\n\nms = read_mesh(\"meshes/flamingo-poses/flam-01.obj\")\n# ms = GeoIO.load(\"meshes/flamingo-poses/flam-01.obj\")\n\nplot_mesh(ms)\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie ~/.julia/packages/Makie/VRavR/src/scenes.jl:220\n\n\n\n\n\n\n# # componentes\n# function barcode_from_mesh(ms, n_points=1000)\n#     X_total = mesh_to_metric_space(ms)\n\n#     g = mesh_to_graph(ms, X_total)\n\n#     componentes_g = connected_components(g)\n#     ids_maior_componente = componentes_g[findmax(length, componentes_g)[2]]\n\n#     X_total = X_total[ids_maior_componente]\n\n#     g = g[ids_maior_componente]\n\n\n#     fts_sample = farthest_points_sample(X_total, n_points)\n#     X = X_total[fts_sample]\n#     D = geodesic_distance_from_graph(g, fts_sample)\n\n#     # force simmetry on X\n#     for i ∈ 1:n_points\n#         for j ∈ i:n_points\n#             D[i, j] = D[j, i]\n#         end\n#     end\n\n#     max_dist = maximum(D)\n#     D = D ./ max_dist\n\n#     pd = ripserer(D, dim_max = 2, verbose=true, sparse = true, threshold = 0.9)\n\n#     pd, D, X, g\n\n# end\n\n# pd, D, X, g = barcode_from_mesh(ms, 300)\n\n# exc = mapslices(sum, D, dims=2) |&gt; vec\n\n# gl.scatter(X, color=exc)\n\n# import Plots\n# Plots.plot(pd)\n# barcode(pd)\n\n\n# calcula pds\n# function list_files(path=\"\", pattern=\"\")\n#     files =\n#         @chain begin\n#             map(walkdir(path)) do (root, dirs, files)\n#                 joinpath.(root, files)\n#             end\n#             reduce(vcat, _)\n#             filter(x -&gt; occursin(pattern, x), _)\n#         end\n\n#     files\n# end\n\n# arquivos = list_files(\"meshes/\", \".obj\")\n\n# arquivos = arquivos[1:5:80]\n\n# analises =\n#     @showprogress desc=\"lendo arquivo...\" map(arquivos) do file\n#         ms = read_mesh(file)\n#         pd, D, X, g = barcode_from_mesh(ms)\n#     end\n\n# analises[1]\n# barcode(analises[1][1])\n\n\n# arquivos = [\n#     \"meshes/flamingo-poses/flam-01.obj\"\n#     ,\"meshes/elephant-poses/elephant-01.obj\"\n# ]\n\n# analises = map(arquivos) do f\n#     ms = read_mesh(f)\n#     barcode_from_mesh(ms, 350)\n# end\n\n# pd, D, X, g = analises[1]\n# exc = mapslices(sum, D, dims=2) |&gt; vec\n# gl.scatter(X, color=exc)\n# barcode(pd)\n\n# pd, D, X, g = analises[2]\n# exc = mapslices(sum, D, dims=2) |&gt; vec\n# gl.scatter(X, color=exc)\n# barcode(pd)\n\n# Bottleneck()(analises[1][1][2:3], analises[2][1][2:3])",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>3d shape classification using persistent homology</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#loading-and-visualizing-the-shapes",
    "href": "3d-shapes.html#loading-and-visualizing-the-shapes",
    "title": "2  3d shape classification using persistent homology",
    "section": "2.2 Loading and visualizing the shapes",
    "text": "2.2 Loading and visualizing the shapes\nLet’s start with a flamingo shape. We load some libraries\n\n# read meshes and plot\nusing Meshes, GeoIO\nimport GLMakie as gl\n\n# see progress\nusing ProgressMeter\n\n# dataframes\nusing DataFramesMeta, CSV, Chain\n\n# metric spaces and graphs\nusing MetricSpaces\nusing Graphs, SimpleWeightedGraphs\n\n# persistent homology\nimport Ripserer\nimport PersistenceDiagrams as Pd\nimport Plots\n\n# comparing the distance matrix\nusing Clustering, StatsPlots\nimport StatisticalMeasures.ConfusionMatrices as CM\n\nand define functions to read and visualize shapes\n\n\nCode\nfunction list_files(path=\"\", pattern=\"\")\n    files =\n        @chain begin\n            map(walkdir(path)) do (root, dirs, files)\n                joinpath.(root, files)\n            end\n            reduce(vcat, _)\n            filter(x -&gt; occursin(pattern, x), _)\n        end\n\n    files\nend;\n\nfunction get_class_files(class)\n    @chain begin list_files(\"meshes/\", class)\n        filter(x -&gt; occursin(\".obj\", x), _)\n    end\nend;\n\nread_mesh(filepath) = GeoIO.load(filepath).geometry;\n\nplot_mesh(ms) = viz(ms, showfacets = true, alpha = 0.5);\n\n\nThe reference pose is the following:\n\nfilepath = \"meshes/flamingo-poses/flam-reference.obj\"\nms = read_mesh(filepath)\n\n52895 SimpleMesh{3,Float64}\n  26907 vertices\n  ├─ Point(-0.0497887, 0.179158, 0.304686)\n  ├─ Point(-0.0478521, 0.176355, 0.337555)\n  ├─ Point(-0.0489072, 0.170843, 0.36641)\n  ├─ Point(-0.0479558, 0.154587, 0.319926)\n  ├─ Point(-0.0484908, 0.148718, 0.356395)\n  ⋮\n  ├─ Point(-0.210709, 0.423044, 0.649643)\n  ├─ Point(-0.211377, 0.439884, 0.657541)\n  ├─ Point(-0.211205, 0.437203, 0.65695)\n  ├─ Point(-0.211346, 0.434063, 0.656262)\n  └─ Point(-0.212218, 0.433793, 0.654967)\n  52895 elements\n  ├─ Triangle(7103, 7102, 9)\n  ├─ Triangle(7106, 7105, 1)\n  ├─ Triangle(7109, 7108, 1)\n  ├─ Triangle(7110, 7105, 2)\n  ├─ Triangle(7110, 7112, 4)\n  ⋮\n  ├─ Triangle(5645, 23075, 23400)\n  ├─ Triangle(23075, 26903, 23400)\n  ├─ Triangle(26905, 7069, 26904)\n  ├─ Triangle(5633, 26905, 23378)\n  └─ Triangle(26905, 26904, 23378)\n\n\nWe can also visualize it as a gif\n\n# fig, ax, plt = plot_mesh(ms);\n\n# gl.record(fig, \"images/3d-shapes/flamingo.gif\", 0:63) do i\n#     gl.rotate!(fig.scene, Vec3f(0, 0, 1), i * pi/32)\n# end;\n\n\nand see its details:\n\nWe can see some variations of the initial pose:\n\nms2 = read_mesh(\"meshes/flamingo-poses/flam-01.obj\")\n\nplot_mesh(ms2)\n\n\n\n\n\nms2 = read_mesh(\"meshes/flamingo-poses/flam-02.obj\")\n\nplot_mesh(ms2)\n\n\n\n\n\nms2 = read_mesh(\"meshes/flamingo-poses/flam-03.obj\")\n\nplot_mesh(ms2)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>3d shape classification using persistent homology</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#setting-the-classification-problem",
    "href": "3d-shapes.html#setting-the-classification-problem",
    "title": "3  3d shape classification",
    "section": "3.3 Setting the classification problem",
    "text": "3.3 Setting the classification problem\nWe have 84 shapes in the following directories:\n\nfilter(!isfile, readdir(\"meshes/\", join = true))\n\n8-element Vector{String}:\n \"meshes/camel-poses\"\n \"meshes/cat-poses\"\n \"meshes/elephant-poses\"\n \"meshes/face-poses\"\n \"meshes/flamingo-poses\"\n \"meshes/head-poses\"\n \"meshes/horse-poses\"\n \"meshes/lion-poses\"\n\n\nEach shape \\(s \\in S\\) has a class of the type camel, cat, elephant, etc. We can think of these classes as a function \\(c: S \\to C\\) where \\(C\\) is the set of classes. Let \\(S_{rp}\\) be the set of reference poses.\nWe will try to solve the following problem: can we correctly calculate \\(c(s)\\) when we only know \\(c\\) for \\(s \\in S_{rp}\\)? That is: knowing only the class of each reference pose, can we deduce the class of the remaining shapes using only the mesh file?\nThis kind of problem is common in data science and is known as a “classification problem”: we are trying to atribute classes to objects, knowing the class of fewer other objects.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#from-meshes-to-metric-spaces",
    "href": "3d-shapes.html#from-meshes-to-metric-spaces",
    "title": "3  3d shape classification",
    "section": "3.4 From meshes to metric spaces",
    "text": "3.4 From meshes to metric spaces\nAs this is a minicourse on topological data analysis, we know that in somewhere we have to use persistent homology.\nAn ingenuous attempt to solve the classification problem can be summarised as follows:\n\nFor each shape \\(S_i\\), extract the points \\(X_i \\subset \\mathbb{R}^3\\) and consider \\(d\\) as the Euclidean distance;\nCalculate the persistence diagram \\(D_i = dgm(X_i)\\);\nFor each \\(D_i\\), calculate the bottleneck distance from \\(D_i\\) to all \\(D_j\\) where \\(S_j\\) is a reference pose;\nThe closest reference pose to \\(D_i\\) will be the class of \\(S_i\\).\n\nThis approach won’t work because of the two first steps:\n\nThe euclidean distance is not appropriate for this problem. Flamingos in different poses will have a big Gromov-Hausdorff distance. We need to use some kind of geodesic distance.\nThe amount of points in \\(X_i\\) is too big to calculate the persistence diagram. The elephant class has more than 75.000 points for each shape. This will probably explode your RAM memory when calculating the Rips complex.\n\nFortunately, there are ways to contourn these problems!\n\nExtract a subset of “reasonably spaced points” of \\(S\\) that still contains its core geometric properties;\nCalculate the geodesic distance between these points using the shape \\(S\\).\n\n\n3.4.1 From meshes to \\(\\mathbb{R}^3\\)\nLet’s extract the points of some \\(S\\) as a subspace of \\(\\mathbb{R}^3\\):\n\nmesh_to_metric_space(ms) = ms.vertices .|&gt; coordinates .|&gt; Vector |&gt; EuclideanSpace;\n\n\nX = mesh_to_metric_space(ms)\n\n26907-element Vector{StaticArraysCore.SVector{3, Float64}}:\n [-0.0497887, 0.179158, 0.304686]\n [-0.0478521, 0.176355, 0.337555]\n [-0.0489072, 0.170843, 0.36641]\n [-0.0479558, 0.154587, 0.319926]\n [-0.0484908, 0.148718, 0.356395]\n [-0.0549708, 0.129732, 0.300859]\n [-0.0529351, 0.125235, 0.325443]\n [-0.0537256, 0.124306, 0.346663]\n [-0.0569744, 0.201286, 0.371339]\n [-0.0536567, 0.19095, 0.297565]\n [-0.0522451, 0.191074, 0.306529]\n [-0.0571656, 0.181709, 0.282749]\n [-0.0524422, 0.185973, 0.296856]\n ⋮\n [-0.209925, 0.44, 0.658976]\n [-0.20707, 0.420017, 0.655563]\n [-0.210662, 0.444178, 0.660018]\n [-0.211038, 0.441635, 0.658588]\n [-0.208734, 0.420334, 0.651864]\n [-0.211586, 0.429432, 0.654244]\n [-0.210811, 0.425791, 0.653265]\n [-0.210709, 0.423044, 0.649643]\n [-0.211377, 0.439884, 0.657541]\n [-0.211205, 0.437203, 0.65695]\n [-0.211346, 0.434063, 0.656262]\n [-0.212218, 0.433793, 0.654967]\n\n\nWe can see that \\(X\\) is made of 26907 points of \\(\\mathbb{R}^3\\). We can plot it:\n\ngl.scatter(X, markersize = 1)\n\n\n\n\n\n\n\n\n\n\n3.4.2 From meshes to graphs\nNow, to calculate the geodesic distance, we will create a graph from the mesh \\(S\\). We define a function\n\n\nCode\nfunction graph_from_mesh(ms)\n    # the set of vertices\n    V = coordinates.(ms.vertices)\n\n    # create an empty graph\n    g = SimpleWeightedGraph()\n\n    # add n vertices to it\n    n = length(V)\n    add_vertices!(g, n)\n\n    # the set of triangles of the mesh ms\n    triangles = ms.topology.connec\n\n    # for each triangle, add its edges to the graph\n    @showprogress desc = \"Adding vertices to graph...\" for t ∈ triangles\n        v1, v2, v3 = t.indices\n        add_edge!(g, v1, v2, dist_euclidean(V[v1], V[v2]))\n        add_edge!(g, v1, v3, dist_euclidean(V[v1], V[v3]))\n        add_edge!(g, v2, v3, dist_euclidean(V[v2], V[v3]))\n    end\n\n    g\nend;\n\n\nand create the graph \\(g\\) from the mesh\n\ng = graph_from_mesh(ms)\n\n{26907, 79244} undirected simple Int64 graph with Float64 weights\n\n\nThis weighted graph is the 1-skeleton of the mesh, and the weights between the vertices are the euclidean distance between then (as subsets of \\(\\mathbb{R}^3\\)).\nWe can see the sparse array of its weight as follows:\n\nweights(g)\n\n26907×26907 SparseArrays.SparseMatrixCSC{Float64, Int64} with 158488 stored entries:\n⎡⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣶⣶⣖⣆⣀⡀⢀⡀⠀⠀⠀⠀⠀⠀⠀⠤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠈⢋⠛⠿⡿⣿⣿⣾⣆⣀⡀⠀⠀⠀⠀⠀⠉⠛⠿⢤⡀⠀⠀⠈⠁⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠛⠻⠿⠷⠷⣦⣀⡀⠀⠀⠀⠀⠀⠉⠙⠂⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠒⠠⠠⠄⡀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠛⠳⢤⣄⣀⠀⠀⠀⠐⢦⠀⎥\n⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠐⠒⠀⠀⠀⠀⠀⠀⢀⡀⠀⠈⠉⠛⠳⠶⣤⣈⠙⎥\n⎢⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠰⣦⣤⣠⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠁⠈⠉⠂⠀⠀⠀⠉⠛⎥\n⎢⢻⣿⡀⠀⠀⠀⠀⠀⠀⠀⠀⣻⣿⣿⣿⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣂⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⢸⢿⡦⢀⠀⠀⢠⠀⠀⠀⠀⠐⠛⢿⢿⣷⣷⡤⡄⢐⠀⠀⠀⠀⠀⠀⠀⠀⠈⠳⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠈⢹⣿⡄⠀⠀⠀⡂⠀⠀⠀⠀⠀⠀⠙⡿⣿⣿⣷⣾⣄⢀⡀⠀⠀⠀⠀⠀⠀⠀⠑⣖⠂⠀⠀⠀⠀⠀⠂⠀⎥\n⎢⠀⢈⣿⣯⡀⠀⠀⠡⡀⠀⠀⠀⠀⠀⢀⢉⣹⣿⣿⣿⣼⣕⣀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢷⡄⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⠈⣻⣿⣷⠀⠀⠀⢃⠀⠀⠀⠀⠀⠀⠀⠀⢙⢖⢿⣿⣿⣧⣲⣀⠀⠀⠀⠀⠀⠀⠀⠀⠸⣄⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠈⢹⣿⡆⠀⠀⠘⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠘⢩⣻⣿⣿⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠹⣧⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠈⢽⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠙⢿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠃⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠈⢻⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠻⣦⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n⎢⠀⢧⠀⠀⠀⠈⣧⠀⠀⢀⠀⠀⠈⠘⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠻⣦⡄⠀⠀⠀⠀⠀⠀⢀⠀⠀⎥\n⎢⠀⠈⣧⠀⠀⠀⠙⣆⠀⠈⠆⠀⠀⠀⠀⠉⢱⢤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠻⣦⡀⠀⠀⠀⠀⠘⢲⠀⎥\n⎢⠀⠀⠛⣇⠀⠀⠀⢹⡆⠀⡆⠀⠀⠀⠀⠀⠈⠀⠙⠷⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣦⡀⠀⠀⠀⢰⣀⎥\n⎢⠀⠀⠀⠈⣇⠀⠀⠀⢿⡀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣦⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠿⣧⣀⠀⠀⠙⎥\n⎢⠀⠀⡀⠀⠈⠀⢀⠀⠘⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠀⠀⠀⠀⢀⣀⠀⠀⠀⠀⠘⠻⣦⡀⠀⎥\n⎣⠀⠀⠁⠀⠀⠀⠈⠓⣆⠘⣧⠀⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠒⠐⢲⣄⠀⠀⠈⠻⣦⎦\n\n\nNotice, however, that the mesh is not connected! This can be seen with\n\nis_connected(g)\n\nfalse\n\n\nThese are the connected components of \\(g\\):\n\nconnected_components(g)\n\n514-element Vector{Vector{Int64}}:\n [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  26898, 26899, 26900, 26901, 26902, 26903, 26904, 26905, 26906, 26907]\n [4032]\n [4036]\n [4039]\n [4042]\n [4046]\n [4047]\n [4048]\n [4049]\n [4050]\n [4077]\n [4099]\n [4100]\n ⋮\n [7089]\n [7090]\n [7091]\n [7092]\n [7093]\n [7094]\n [7095]\n [7096]\n [7097]\n [7098]\n [7099]\n [7100]\n\n\nThere is one big connected components, and several smaller ones with 1 point each. Let’s extract the one with the most points and throw away the points of \\(X\\) outside it.\n\n\nCode\nfunction extract_biggest_connected_component(g)\n    cc_components = connected_components(g)\n    ids_biggest_component = cc_components[findmax(length, cc_components)[2]]\n\n    # modify the graph g on place\n    g = g[ids_biggest_component]\n\n    # return g and the ids of the biggest connected component\n    g, ids_biggest_component\nend;\n\n\n\ng, ids_biggest_component = extract_biggest_connected_component(g);\n\nWe can see that \\(g\\) now is connected:\n\nis_connected(g)\n\ntrue\n\n\nLet’s throw away from \\(X\\) the points outside this component:\n\nX = X[ids_biggest_component]\n\n26394-element Vector{StaticArraysCore.SVector{3, Float64}}:\n [-0.0497887, 0.179158, 0.304686]\n [-0.0478521, 0.176355, 0.337555]\n [-0.0489072, 0.170843, 0.36641]\n [-0.0479558, 0.154587, 0.319926]\n [-0.0484908, 0.148718, 0.356395]\n [-0.0549708, 0.129732, 0.300859]\n [-0.0529351, 0.125235, 0.325443]\n [-0.0537256, 0.124306, 0.346663]\n [-0.0569744, 0.201286, 0.371339]\n [-0.0536567, 0.19095, 0.297565]\n [-0.0522451, 0.191074, 0.306529]\n [-0.0571656, 0.181709, 0.282749]\n [-0.0524422, 0.185973, 0.296856]\n ⋮\n [-0.209925, 0.44, 0.658976]\n [-0.20707, 0.420017, 0.655563]\n [-0.210662, 0.444178, 0.660018]\n [-0.211038, 0.441635, 0.658588]\n [-0.208734, 0.420334, 0.651864]\n [-0.211586, 0.429432, 0.654244]\n [-0.210811, 0.425791, 0.653265]\n [-0.210709, 0.423044, 0.649643]\n [-0.211377, 0.439884, 0.657541]\n [-0.211205, 0.437203, 0.65695]\n [-0.211346, 0.434063, 0.656262]\n [-0.212218, 0.433793, 0.654967]\n\n\nWe now have 26394 points, which is a small reduction.\n\n\n3.4.3 Farthest points sampling\nWe could just select a random sample of points from our space, but points in high-density areas would be selected a lot more. There is another way to select points in a “well spaced manner”, called the farthest point sampling algorithm. This algorithm was shown to me by Facundo Mémoli on a dirty blackboard in 2018 and the simplicity of it astonished me. For the curious ones, the algorithm is detailed below.\n\n\n\n\n\n\nImportant\n\n\n\n\nLet \\((X, d)\\) be a metric space. Fix an integer \\(n\\). Let \\(C = \\emptyset\\) be the “set of chosen points”. Select \\(x_1 \\in X\\) randomly and add it to \\(C\\). Repeat the following procedure until you have \\(n\\) points in \\(C\\):\n\nCalculate the point \\(x \\in X\\) that is the most distant from all elements of \\(C\\), ie, \\[\n\\max \\{ d(x, c), c \\in C \\} = \\max \\{d(x', c), x' \\in X, c \\in C \\}.\n\\]\nAdd \\(x\\) to \\(C\\).\nIf \\(C\\) has \\(n\\) points, stop.\n\nThe set \\(C\\) is called a farthest points sampling of \\(X\\) with size \\(n\\).\nNotice that running the algorithm several times can lead to different sets \\(C\\) because the first term is chosen randomly.\n\n\nLet’s extract 400 points with the FPS algorithm and the euclidean distance:\n\nids_fps = farthest_points_sample(X, 400);\nX_fps = X[ids_fps]\n\n400-element Vector{StaticArraysCore.SVector{3, Float64}}:\n [-0.107022, 0.039553, 0.364736]\n [-0.195649, 0.502407, 0.660994]\n [-0.270087, -0.46859, 0.403179]\n [-0.182738, 0.119117, 0.00595822]\n [-0.185254, 0.166114, 0.667362]\n [-0.117639, -0.24336, 0.303398]\n [-0.237138, 0.268494, 0.247062]\n [-0.115106, 0.260205, 0.465339]\n [-0.299734, 0.136075, 0.423236]\n [-0.0880564, 0.140974, 0.190074]\n [-0.246111, -0.0966413, 0.33537]\n [-0.255704, 0.0859757, 0.251713]\n [-0.0868923, -0.467545, 0.403375]\n ⋮\n [-0.256754, 0.156461, 0.143168]\n [-0.158485, 0.128119, 0.588432]\n [-0.246906, -0.218068, 0.333071]\n [-0.151287, 0.455073, 0.618865]\n [-0.202332, 0.104544, 0.0852435]\n [-0.223042, 0.0471532, 0.326987]\n [-0.0720166, 0.220807, 0.280532]\n [-0.222668, 0.283441, 0.397288]\n [-0.176906, 0.206205, 0.124522]\n [-0.213914, 0.0725748, 0.424124]\n [-0.16763, 0.359415, 0.688994]\n [-0.163011, 0.149323, 0.659159]\n\n\n\ngl.scatter(X_fps, markersize = 10)\n\n\n\n\n\n\n\n\nThis is a very good approximation!\nWe are now interested in calculating the geodesic distance between these 400 points. But be careful! The geodesic distance need the entire mesh to work.\n\n\n3.4.4 Geodesic distances\nGiven a shape \\(S\\), we can think of the geodesic distance between two points as “the least distance an and would need to walk from one point to another”. We will approximate this “walkable” paths using the edges of the triangles of the shape \\(S\\). Remember: a mesh is a set of points and triangles!\nThe Dijkstra algorithm is perfect for our needs: it calculates the shortest path from one point to another in a weighted graph. So all we need is to:\n\nTransform \\(S\\) into a graph where the edges have weights (the euclidean distance between these points);\nCalculate the shortest path between each two points.\n\nWe already have the first item, so let’s calculate the second.\n\n\nCode\nfunction geodesic_distance_from_graph(g, ids)\n    n = length(ids)\n    D = zeros(n, n)\n\n    # for each point, calculate the distance from it to every other point of g\n    @showprogress desc = \"Calculating geodesic distance...\" Threads.@threads for (i, id) ∈ collect(enumerate(ids))\n        dts = dijkstra_shortest_paths(g, id)\n        D[i, :] = dts.dists[ids]\n    end\n\n    # force simmetry on X, because of small difference\n    # in the calculation of paths\n    for i ∈ 1:n\n        for j ∈ i:n\n            D[i, j] = D[j, i]\n        end\n    end\n\n    # normalize the distance so the max is 1\n    max_dist = maximum(D)\n    D = D ./ max_dist\n\n    return D\nend;\n\n\n\nD = geodesic_distance_from_graph(g, ids_fps)\n\n400×400 Matrix{Float64}:\n 0.0        0.527399   0.496126  …  0.0990542  0.558501   0.236787\n 0.527399   0.0        0.920468     0.468136   0.113297   0.323703\n 0.496126   0.920468   0.0          0.453372   0.95784    0.64461\n 0.274108   0.78145    0.659985     0.317396   0.818821   0.494161\n 0.258721   0.312436   0.650628     0.197256   0.345697   0.0273031\n 0.204747   0.722805   0.667214  …  0.284132   0.753907   0.432192\n 0.296385   0.624629   0.624996     0.252588   0.662      0.357959\n 0.19343    0.473361   0.656623     0.219979   0.508965   0.195526\n 0.177211   0.472754   0.503389     0.0809706  0.510125   0.209687\n 0.152412   0.644772   0.579899     0.220367   0.676968   0.356241\n 0.189861   0.615849   0.310651  …  0.148902   0.65322    0.34014\n 0.14986    0.599894   0.479458     0.141972   0.637266   0.332694\n 0.410425   0.927863   0.873611     0.489035   0.958965   0.637251\n ⋮                               ⋱                        \n 0.232703   0.678384   0.575604     0.236981   0.715756   0.415318\n 0.184372   0.343158   0.60037      0.147989   0.37439    0.0554781\n 0.272149   0.696283   0.226129  …  0.229219   0.733655   0.420458\n 0.483192   0.0753458  0.88335      0.431018   0.0877104  0.279646\n 0.22421    0.723614   0.601306     0.25956    0.760985   0.436325\n 0.0993721  0.546648   0.414913     0.0788641  0.584019   0.265419\n 0.157096   0.58501    0.626734     0.241333   0.619522   0.300161\n 0.279329   0.52523    0.631455  …  0.217739   0.562602   0.256681\n 0.260941   0.727708   0.656291     0.31212    0.76222    0.442859\n 0.0990542  0.468136   0.453372     0.0        0.505507   0.19146\n 0.558501   0.113297   0.95784      0.505507   0.0        0.354955\n 0.236787   0.323703   0.64461      0.19146    0.354955   0.0\n\n\nWe can see that \\(D\\) makes sense just by plotting \\(X_fps\\) colored by the sum of the distances to each points:\n\nexc = map(sum, eachcol(D))\n\ngl.scatter(X_fps, color = exc, markersize = 10)\n\n\n\n\n\n\n\n\nLooks good! The extremities of the flamingo are in a lighter color, indicating that the sum of the distances there is bigger. Now we have 1000 points sampled from \\(S\\), together with the geodesic distance.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#persistent-homology",
    "href": "3d-shapes.html#persistent-homology",
    "title": "3  3d shape classification",
    "section": "3.5 Persistent homology",
    "text": "3.5 Persistent homology\nWe can now calculate the persistence diagram of \\(X_fps\\) with the geodesic distance and use it! Let’s load some packages and calculate it\n\npd = Ripserer.ripserer(D, dim_max = 2, verbose=true, sparse = true, threshold = 0.4)\n\n3-element Vector{PersistenceDiagrams.PersistenceDiagram}:\n 400-element 0-dimensional PersistenceDiagram\n 204-element 1-dimensional PersistenceDiagram\n 11-element 2-dimensional PersistenceDiagram\n\n\nPloting the intervals looks as follows:\n\n\nCode\nfunction plot_barcode(pd)\n    # get the size of the longest interval\n    threshold = \n        @chain begin\n            vcat(pd...)\n            last.(_)\n            filter(isfinite, _)\n            maximum\n        end\n\n    # plot the barcode using this interval as the maximum value of the x-axis\n    Ripserer.barcode(pd, infinity = threshold)\nend;\n\n\n\nplot_barcode(pd)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nor just the 1- and 2-dimensional barcode:\n\nplot_barcode(pd[2:3])",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#summarizing",
    "href": "3d-shapes.html#summarizing",
    "title": "3  3d shape classification",
    "section": "3.6 Summarizing",
    "text": "3.6 Summarizing\nAll the hard work on the previous sections was just to prepare our dataset from file to barcode. That’s why they say that data science is 80% preparing the data and 20% analyzing it!\nWe can summarise what we did with the following function:\n\n\nCode\nfunction file_to_barcode(filepath; n_points = 1000, dim_max = 1)\n    ms = read_mesh(filepath)\n\n    X = mesh_to_metric_space(ms)\n    g = graph_from_mesh(ms)\n\n    g, ids_biggest_component = extract_biggest_connected_component(g)\n    X = X[ids_biggest_component]\n\n    ids_fps = farthest_points_sample(X, n_points);\n    X_fps = X[ids_fps]\n\n    D = geodesic_distance_from_graph(g, ids_fps)\n\n    pd = Ripserer.ripserer(D, dim_max = dim_max, verbose=true, sparse = true, threshold = 0.8)\n\n    return X_fps, D, pd\nend;\n\n\nWe also define some functions to save the barcodes and metric spaces to disk, so we don’t have to calculate all of them in a single session. Calculating the 2-dimensional barcode can take some time depending on your hardware!\n\n\nCode\nfunction pd_to_dataframe(pd)\n    df = @chain begin\n        map(pd) do p\n            DataFrame(\n                birth=p .|&gt; first, death=p .|&gt; last, dim=p.dim\n            )\n        end\n        vcat(_...)\n    end\n\n    df\nend;\n\nfunction dataframe_to_pd(df)\n    df.threshold .= 1\n\n    @chain df begin\n        groupby(:dim)\n        collect\n        map(Pd.PersistenceDiagram, _)\n    end\nend;\n\nfunction metric_space_to_df(X) \n    @chain X_fps begin\n        stack\n        transpose\n        DataFrame(_, :auto)\n    end\nend;\n\n\nNow we loop over all meshes, calculate its persistence diagram and save it to disk, together with the \\(X_{fps}\\) metric space as above.\nImportant: This can take some time! If you cloned my github repository, these files are already there, so you can skip the following piece of code:\n\noverwrite_old_files = true\n\n@showprogress \"Calculating barcode...\" for file ∈ list_files(\"meshes/\", \".obj\") \n    println(\"Calculating barcode from file $file ...\")\n\n    file_pd = replace(file, \".obj\" =&gt; \"-pd.csv\")\n    # skip if there is a file already\n    if isfile(file_pd) & !overwrite_old_files continue end\n\n    X_fps, D, pd = file_to_barcode(file, n_points = 350, dim_max = 2)\n    df = pd_to_dataframe(pd)\n\n    CSV.write(file_pd, df)\n\n    file_X = replace(file, \".obj\" =&gt; \"-points.csv\")\n    CSV.write(file_X, metric_space_to_df(X_fps))\nend\n\nWe read the persistence diagrams saved on disk and pass them to table (a DataFrame object), but first we throw away small intervals.\n\n\nCode\nfunction throw_away_small_intervals(pd, min_pers = 0.01)\n    map(pd) do p\n        filter(x -&gt; Pd.persistence(x) &gt; min_pers, p)\n    end\nend;\n\nfunction read_pds_from_files(directory, min_interval_size = 0.05)\n  pds_df = DataFrame()\n\n#   file = list_files(\"meshes/\", \"-pd.csv\")[1]\n  for file ∈ list_files(directory, \"-pd.csv\")\n\n      pd = @chain begin\n          CSV.read(file, DataFrame)\n          dataframe_to_pd(_)\n          throw_away_small_intervals(min_interval_size)\n      end\n\n      name = replace(file, \"-pd.csv\" =&gt; \"\")\n      push!(pds_df, (Path = name, Persistence_diagram = pd))\n  end\n\n  pds_df\n\n  sort!(pds_df, :Path)\n\n  pds_df.File = [split(s, \"/\")[3] for s ∈ pds_df.Path]\n  pds_df.Class = [split(s, \"-\")[1] for s ∈ pds_df.File]\n\n  pds_df\nend;",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#in-the-mounts-of-distance",
    "href": "3d-shapes.html#in-the-mounts-of-distance",
    "title": "2  3d shape classification using persistent homology",
    "section": "2.7 In the mounts of distance",
    "text": "2.7 In the mounts of distance\n!!! Now we proceed to create a dataframe\n\npds_df = read_pds_from_files(\"meshes/\", 0.01)\n\n83×4 DataFrame58 rows omitted\n\n\n\nRow\nPath\nPersistence_diagram\nFile\nClass\n\n\n\nString\nArray…\nSubStrin…\nSubStrin…\n\n\n\n\n1\nmeshes/camel-poses/camel-01\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 64-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-01\ncamel\n\n\n2\nmeshes/camel-poses/camel-02\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 62-element 1-dimensional PersistenceDiagram, 5-element 2-dimensional PersistenceDiagram]\ncamel-02\ncamel\n\n\n3\nmeshes/camel-poses/camel-03\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 79-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-03\ncamel\n\n\n4\nmeshes/camel-poses/camel-04\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 75-element 1-dimensional PersistenceDiagram, 3-element 2-dimensional PersistenceDiagram]\ncamel-04\ncamel\n\n\n5\nmeshes/camel-poses/camel-05\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 68-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-05\ncamel\n\n\n6\nmeshes/camel-poses/camel-06\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 71-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-06\ncamel\n\n\n7\nmeshes/camel-poses/camel-07\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 78-element 1-dimensional PersistenceDiagram, 4-element 2-dimensional PersistenceDiagram]\ncamel-07\ncamel\n\n\n8\nmeshes/camel-poses/camel-08\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 73-element 1-dimensional PersistenceDiagram, 4-element 2-dimensional PersistenceDiagram]\ncamel-08\ncamel\n\n\n9\nmeshes/camel-poses/camel-09\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 83-element 1-dimensional PersistenceDiagram, 5-element 2-dimensional PersistenceDiagram]\ncamel-09\ncamel\n\n\n10\nmeshes/camel-poses/camel-10\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 79-element 1-dimensional PersistenceDiagram, 3-element 2-dimensional PersistenceDiagram]\ncamel-10\ncamel\n\n\n11\nmeshes/camel-poses/camel-reference\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 70-element 1-dimensional PersistenceDiagram, 5-element 2-dimensional PersistenceDiagram]\ncamel-reference\ncamel\n\n\n12\nmeshes/cat-poses/cat-01\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 87-element 1-dimensional PersistenceDiagram, 11-element 2-dimensional PersistenceDiagram]\ncat-01\ncat\n\n\n13\nmeshes/cat-poses/cat-02\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 73-element 1-dimensional PersistenceDiagram, 10-element 2-dimensional PersistenceDiagram]\ncat-02\ncat\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n72\nmeshes/horse-poses/horse-09\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 68-element 1-dimensional PersistenceDiagram, 11-element 2-dimensional PersistenceDiagram]\nhorse-09\nhorse\n\n\n73\nmeshes/horse-poses/horse-10\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 85-element 1-dimensional PersistenceDiagram, 11-element 2-dimensional PersistenceDiagram]\nhorse-10\nhorse\n\n\n74\nmeshes/lion-poses/lion-01\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 85-element 1-dimensional PersistenceDiagram, 12-element 2-dimensional PersistenceDiagram]\nlion-01\nlion\n\n\n75\nmeshes/lion-poses/lion-02\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 91-element 1-dimensional PersistenceDiagram, 14-element 2-dimensional PersistenceDiagram]\nlion-02\nlion\n\n\n76\nmeshes/lion-poses/lion-03\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 104-element 1-dimensional PersistenceDiagram, 21-element 2-dimensional PersistenceDiagram]\nlion-03\nlion\n\n\n77\nmeshes/lion-poses/lion-04\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 96-element 1-dimensional PersistenceDiagram, 13-element 2-dimensional PersistenceDiagram]\nlion-04\nlion\n\n\n78\nmeshes/lion-poses/lion-05\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 87-element 1-dimensional PersistenceDiagram, 14-element 2-dimensional PersistenceDiagram]\nlion-05\nlion\n\n\n79\nmeshes/lion-poses/lion-06\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 91-element 1-dimensional PersistenceDiagram, 13-element 2-dimensional PersistenceDiagram]\nlion-06\nlion\n\n\n80\nmeshes/lion-poses/lion-07\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 90-element 1-dimensional PersistenceDiagram, 12-element 2-dimensional PersistenceDiagram]\nlion-07\nlion\n\n\n81\nmeshes/lion-poses/lion-08\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 101-element 1-dimensional PersistenceDiagram, 10-element 2-dimensional PersistenceDiagram]\nlion-08\nlion\n\n\n82\nmeshes/lion-poses/lion-09\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 98-element 1-dimensional PersistenceDiagram, 15-element 2-dimensional PersistenceDiagram]\nlion-09\nlion\n\n\n83\nmeshes/lion-poses/lion-reference\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 97-element 1-dimensional PersistenceDiagram, 13-element 2-dimensional PersistenceDiagram]\nlion-reference\nlion\n\n\n\n\n\n\nThe dataframe looks ok! You can plot the barcodes as follows:\n\npd2 = pds_df.Persistence_diagram[1]\nplot_barcode(pd2[2:3])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we calculate the bootleneck distance between each pair of persistence diagrams. This can take some time! If you cloned the repository, you don’t need to run this piece of code.\n\npds = pds_df.Persistence_diagram\n\nDB = zeros(83, 83)\n\n@showprogress for i ∈ 1:83\n    for j ∈ i:83\n        if i == j\n            DB[i, j] = 0 \n            continue \n        end\n\n        DB[i, j] = \n            Pd.Bottleneck()(pds[i][2], pds[j][2]) + \n            Pd.Bottleneck()(pds[i][3], pds[j][3])\n\n        DB[j, i] = DB[i, j]\n    end\nend\n\nCSV.write(\"meshes/bottleneck_distance.csv\", DataFrame(DB, :auto))\n\nNotice that we defined the distance \\(DB_{i, j}\\) between two shapes \\(X_i\\) and \\(X_j\\) as\n\\[\nDB_{i, j} = d_b(dgm_1(X_i), dgm_1(X_j)) + d_b(dgm_2(X_i), dgm_2(X_j))\n\\]\nwhere \\(d_b\\) is the bottleneck distance, and \\(dgm_i\\) is the \\(i\\)-dimensional persistence diagram.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>3d shape classification using persistent homology</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#the-moment-of-truth",
    "href": "3d-shapes.html#the-moment-of-truth",
    "title": "2  3d shape classification using persistent homology",
    "section": "2.8 The moment of truth",
    "text": "2.8 The moment of truth\nWe read \\(DB\\) from disk, in case you did not calculate it previously\n\nDB = CSV.read(\"meshes/bottleneck_distance.csv\", DataFrame) |&gt; Matrix\nDB\n\n83×83 Matrix{Float64}:\n 0.0        0.0295622  0.0290437  …  0.0607949  0.0572987  0.0555027\n 0.0295622  0.0        0.0243571     0.0771963  0.0725624  0.0726897\n 0.0290437  0.0243571  0.0           0.0751122  0.0706953  0.07074\n 0.0250842  0.0221888  0.0246823     0.0699059  0.0653315  0.0658234\n 0.0192733  0.0247452  0.0230421     0.0647476  0.062099   0.0607826\n 0.0300337  0.0257192  0.014413   …  0.0729532  0.0680901  0.0688222\n 0.0270758  0.0372715  0.0355232     0.0541806  0.0491843  0.0458797\n 0.0239714  0.0229871  0.0240051     0.0654462  0.0644016  0.0613805\n 0.0354928  0.0229931  0.0236201     0.0807913  0.0765014  0.0759065\n 0.0282784  0.0247452  0.0209122     0.0744052  0.0719081  0.0700331\n 0.0242075  0.0255816  0.0278271  …  0.0672653  0.0677038  0.0630916\n 0.0671795  0.0780996  0.0795003     0.0520017  0.0460498  0.0740998\n 0.0622585  0.076908   0.0745496     0.0303738  0.0299614  0.0425986\n ⋮                                ⋱  ⋮                     \n 0.0565404  0.0753205  0.0781827     0.0349974  0.0455993  0.0281456\n 0.053006   0.0704997  0.0687614     0.0305132  0.0366311  0.0263213\n 0.0745802  0.0753067  0.0726818     0.0587221  0.0524114  0.0815307\n 0.0505002  0.0651497  0.0599707     0.0282434  0.0248999  0.0497492\n 0.055084   0.0697334  0.0664574  …  0.0302786  0.0304893  0.0361665\n 0.0601642  0.0705143  0.066331      0.0346506  0.0309857  0.0538022\n 0.0512327  0.06873    0.0667174     0.0254585  0.0252535  0.0252038\n 0.0504608  0.0675057  0.0672269     0.0248009  0.0211124  0.0363764\n 0.061205   0.0701361  0.0729084     0.0441923  0.0406347  0.066897\n 0.0607949  0.0771963  0.0751122  …  0.0        0.0247205  0.0250417\n 0.0572987  0.0725624  0.0706953     0.0247205  0.0        0.0356727\n 0.0555027  0.0726897  0.07074       0.0250417  0.0356727  0.0\n\n\n\nlabels = pds_df.Class |&gt; copy\nfor i ∈ 2:length(pds_df.Class)\n    if labels[i] == pds_df.Class[i-1]\n        labels[i] = \"\"\n    end\nend\n\nlabels = (1:83, labels)\n\nplot(DB, st = :heatmap, xticks = labels, yticks = labels)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\nCode\nfunction plot_hc(hc)\n    plot(\n        hc, xticks = (1:83, pds_df.File[hc.order])\n        , xflip = true, xrotation = 270\n        , xtickfont = font(5, \"Roboto\")\n        )\nend;\n\n\nThe single linkage dendrogram is a mess\n\nhclust(DB, linkage=:single, branchorder = :optimal) |&gt; plot_hc\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhead-04-grin\n\n\nhead-05-laugh\n\n\nhead-02-cry\n\n\nhead-reference\n\n\nhead-07-sad\n\n\nhead-09-surprise\n\n\nhead-08-smile\n\n\nhead-03-fury\n\n\nhead-01-anger\n\n\nhead-06-rage\n\n\nface-08-smile\n\n\nface-01-anger\n\n\nface-09-surprise\n\n\nface-07-sad\n\n\nface-reference\n\n\nface-06-rage\n\n\nelephant-03\n\n\nelephant-02\n\n\nelephant-08\n\n\nelephant-reference\n\n\nelephant-05\n\n\nelephant-06\n\n\nelephant-07\n\n\nelephant-10\n\n\nelephant-04\n\n\nelephant-01\n\n\ncat-07\n\n\nlion-01\n\n\ncat-01\n\n\nlion-07\n\n\ncat-04\n\n\nlion-03\n\n\ncat-reference\n\n\ncat-08\n\n\ncat-09\n\n\ncat-02\n\n\ncat-03\n\n\ncat-06\n\n\nlion-02\n\n\nlion-08\n\n\nlion-09\n\n\nlion-06\n\n\nlion-05\n\n\nlion-reference\n\n\nhorse-03\n\n\nhorse-10\n\n\nhorse-08\n\n\nhorse-06\n\n\nhorse-05\n\n\nhorse-07\n\n\nhorse-02\n\n\nhorse-09\n\n\nhorse-04\n\n\nhorse-01\n\n\nlion-04\n\n\ncat-05\n\n\nflam-04\n\n\nflam-05\n\n\nflam-06\n\n\nflam-03\n\n\nflam-02\n\n\nflam-08\n\n\nflam-01\n\n\nflam-10\n\n\nflam-reference\n\n\nflam-07\n\n\nflam-09\n\n\ncamel-reference\n\n\ncamel-01\n\n\ncamel-05\n\n\ncamel-08\n\n\ncamel-10\n\n\ncamel-03\n\n\ncamel-06\n\n\ncamel-09\n\n\ncamel-02\n\n\ncamel-04\n\n\ncamel-07\n\n\nelephant-09\n\n\nface-03-fury\n\n\nface-02-cry\n\n\nface-05-laugh\n\n\nface-04-grin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBut the complete shows more hope:\n\nhclust(DB, linkage = :complete, branchorder = :optimal) |&gt; plot_hc\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nflam-09\n\n\nflam-07\n\n\nflam-08\n\n\nflam-01\n\n\nflam-10\n\n\nflam-reference\n\n\nflam-03\n\n\nflam-02\n\n\nflam-06\n\n\nflam-05\n\n\nflam-04\n\n\ncamel-04\n\n\ncamel-02\n\n\ncamel-03\n\n\ncamel-06\n\n\ncamel-09\n\n\ncamel-10\n\n\ncamel-08\n\n\ncamel-reference\n\n\ncamel-05\n\n\ncamel-01\n\n\ncamel-07\n\n\nhorse-01\n\n\nhorse-09\n\n\nhorse-04\n\n\nhorse-03\n\n\nhorse-10\n\n\nhorse-02\n\n\nlion-reference\n\n\nlion-05\n\n\nhorse-07\n\n\nhorse-05\n\n\nhorse-08\n\n\nhorse-06\n\n\ncat-reference\n\n\ncat-05\n\n\nlion-06\n\n\nlion-09\n\n\nlion-08\n\n\ncat-06\n\n\ncat-04\n\n\ncat-03\n\n\ncat-02\n\n\ncat-09\n\n\ncat-08\n\n\nlion-03\n\n\nlion-02\n\n\nlion-04\n\n\nlion-01\n\n\ncat-01\n\n\nlion-07\n\n\ncat-07\n\n\nelephant-reference\n\n\nelephant-08\n\n\nelephant-02\n\n\nelephant-05\n\n\nelephant-10\n\n\nelephant-07\n\n\nelephant-06\n\n\nelephant-04\n\n\nelephant-01\n\n\nelephant-03\n\n\nelephant-09\n\n\nhead-reference\n\n\nhead-07-sad\n\n\nhead-06-rage\n\n\nhead-01-anger\n\n\nhead-09-surprise\n\n\nhead-08-smile\n\n\nhead-03-fury\n\n\nhead-02-cry\n\n\nhead-05-laugh\n\n\nhead-04-grin\n\n\nface-06-rage\n\n\nface-09-surprise\n\n\nface-01-anger\n\n\nface-reference\n\n\nface-07-sad\n\n\nface-08-smile\n\n\nface-04-grin\n\n\nface-05-laugh\n\n\nface-02-cry\n\n\nface-03-fury\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is also the Ward algorithm:\n\nhclust(DB, linkage = :ward, branchorder = :optimal) |&gt; plot_hc\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncamel-04\n\n\ncamel-02\n\n\ncamel-03\n\n\ncamel-06\n\n\ncamel-09\n\n\ncamel-reference\n\n\ncamel-08\n\n\ncamel-10\n\n\ncamel-01\n\n\ncamel-05\n\n\ncamel-07\n\n\nflam-02\n\n\nflam-03\n\n\nflam-reference\n\n\nflam-10\n\n\nflam-01\n\n\nflam-08\n\n\nflam-04\n\n\nflam-05\n\n\nflam-06\n\n\nflam-07\n\n\nflam-09\n\n\ncat-reference\n\n\nhorse-01\n\n\nhorse-09\n\n\nhorse-04\n\n\nhorse-03\n\n\nhorse-10\n\n\nhorse-02\n\n\nhorse-07\n\n\nhorse-05\n\n\nhorse-08\n\n\nhorse-06\n\n\nlion-08\n\n\nlion-reference\n\n\nlion-05\n\n\ncat-05\n\n\nlion-06\n\n\nlion-09\n\n\ncat-06\n\n\ncat-03\n\n\ncat-02\n\n\ncat-09\n\n\ncat-08\n\n\ncat-04\n\n\nlion-02\n\n\nlion-03\n\n\nlion-04\n\n\nlion-01\n\n\ncat-01\n\n\nlion-07\n\n\ncat-07\n\n\nelephant-reference\n\n\nelephant-08\n\n\nelephant-02\n\n\nelephant-05\n\n\nelephant-10\n\n\nelephant-07\n\n\nelephant-06\n\n\nelephant-04\n\n\nelephant-01\n\n\nelephant-03\n\n\nelephant-09\n\n\nhead-04-grin\n\n\nhead-05-laugh\n\n\nhead-02-cry\n\n\nhead-03-fury\n\n\nhead-08-smile\n\n\nhead-09-surprise\n\n\nhead-01-anger\n\n\nhead-06-rage\n\n\nhead-07-sad\n\n\nhead-reference\n\n\nface-06-rage\n\n\nface-09-surprise\n\n\nface-01-anger\n\n\nface-reference\n\n\nface-07-sad\n\n\nface-08-smile\n\n\nface-04-grin\n\n\nface-05-laugh\n\n\nface-02-cry\n\n\nface-03-fury\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow let’s calculate for each shape which reference class is closer to it:\n\n\nCode\nget_class_from_file(x) = split(x, \"-\")[1]\n\n\nget_class_from_file (generic function with 1 method)\n\n\n\nscore = @select(pds_df, :Path, :File, :Class)\n\nscore.Nearest_class .= \"\"\n\nids_reference = findall(x -&gt; occursin(\"-reference\", x), score.Path)\nnames_reference = score.File[ids_reference]\n\nfor i ∈ 1:83\n    id = sortperm(DB[i, ids_reference])[1]\n    score.Nearest_class[i] = names_reference[id]\nend\n\nscore\n\n83×4 DataFrame58 rows omitted\n\n\n\nRow\nPath\nFile\nClass\nNearest_class\n\n\n\nString\nSubStrin…\nSubStrin…\nString\n\n\n\n\n1\nmeshes/camel-poses/camel-01\ncamel-01\ncamel\ncamel-reference\n\n\n2\nmeshes/camel-poses/camel-02\ncamel-02\ncamel\ncamel-reference\n\n\n3\nmeshes/camel-poses/camel-03\ncamel-03\ncamel\ncamel-reference\n\n\n4\nmeshes/camel-poses/camel-04\ncamel-04\ncamel\ncamel-reference\n\n\n5\nmeshes/camel-poses/camel-05\ncamel-05\ncamel\ncamel-reference\n\n\n6\nmeshes/camel-poses/camel-06\ncamel-06\ncamel\ncamel-reference\n\n\n7\nmeshes/camel-poses/camel-07\ncamel-07\ncamel\ncamel-reference\n\n\n8\nmeshes/camel-poses/camel-08\ncamel-08\ncamel\ncamel-reference\n\n\n9\nmeshes/camel-poses/camel-09\ncamel-09\ncamel\ncamel-reference\n\n\n10\nmeshes/camel-poses/camel-10\ncamel-10\ncamel\ncamel-reference\n\n\n11\nmeshes/camel-poses/camel-reference\ncamel-reference\ncamel\ncamel-reference\n\n\n12\nmeshes/cat-poses/cat-01\ncat-01\ncat\nelephant-reference\n\n\n13\nmeshes/cat-poses/cat-02\ncat-02\ncat\nlion-reference\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n72\nmeshes/horse-poses/horse-09\nhorse-09\nhorse\nlion-reference\n\n\n73\nmeshes/horse-poses/horse-10\nhorse-10\nhorse\nlion-reference\n\n\n74\nmeshes/lion-poses/lion-01\nlion-01\nlion\nelephant-reference\n\n\n75\nmeshes/lion-poses/lion-02\nlion-02\nlion\nelephant-reference\n\n\n76\nmeshes/lion-poses/lion-03\nlion-03\nlion\nlion-reference\n\n\n77\nmeshes/lion-poses/lion-04\nlion-04\nlion\nelephant-reference\n\n\n78\nmeshes/lion-poses/lion-05\nlion-05\nlion\nlion-reference\n\n\n79\nmeshes/lion-poses/lion-06\nlion-06\nlion\nlion-reference\n\n\n80\nmeshes/lion-poses/lion-07\nlion-07\nlion\nelephant-reference\n\n\n81\nmeshes/lion-poses/lion-08\nlion-08\nlion\nlion-reference\n\n\n82\nmeshes/lion-poses/lion-09\nlion-09\nlion\nlion-reference\n\n\n83\nmeshes/lion-poses/lion-reference\nlion-reference\nlion\nlion-reference\n\n\n\n\n\n\n\nscore.Right_class =\n    get_class_from_file.(score.Class) .== \n    get_class_from_file.(score.Nearest_class)\n\n83-element BitVector:\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 0\n 0\n ⋮\n 0\n 0\n 0\n 0\n 1\n 0\n 1\n 1\n 0\n 1\n 1\n 1\n\n\nOur accuracy was\n\nscore.Right_class |&gt; mean\n\n0.7228915662650602\n\n\nHere is the confusion matrix:\n\nscore_new = @rsubset score !occursin(\"ref\", :File)\nx = CM.confmat(get_class_from_file.(score_new.Nearest_class), score_new.Class)\n\n8×8 Matrix{Int64}:\n 10  0   0  0   0  0  0  0\n  0  1   0  0   0  0  1  0\n  0  2  10  0   0  0  0  4\n  0  0   0  9   0  1  0  0\n  0  0   0  0  10  0  0  0\n  0  0   0  0   0  8  0  0\n  0  0   0  0   0  0  0  0\n  0  6   0  0   0  0  9  5\n\n\n\n\n\nConfusion matrix for DB.\n\n\n\n# using MultivariateStats\n# M = fit(MDS, DB; distances = true, maxoutdim = 3)\n# Y = predict(M)\n\n# score.Row = 1:length(score.Class)\n\n# dfs = @chain score begin\n#     groupby(:Class)\n#     collect\n# end\n\n# fig = gl.Figure();\n# ax = gl.Axis3(fig[1,1])\n\n# for (i, df) ∈ enumerate(dfs)\n    \n#     gl.scatter!(ax, Y[:, df.Row], label = df.Class[1])\n    \n# end\n\n# gl.axislegend();\n\nCan we do better?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>3d shape classification using persistent homology</span>"
    ]
  },
  {
    "objectID": "index.html#why-julia",
    "href": "index.html#why-julia",
    "title": "TDA Workshop - EBT 2024",
    "section": "1.1 Why Julia?",
    "text": "1.1 Why Julia?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#why-tda",
    "href": "index.html#why-tda",
    "title": "TDA Workshop - EBT 2024",
    "section": "1.2 Why TDA?",
    "text": "1.2 Why TDA?\nTopological Data Analysis is a very curious field of mathematics that apply tools from topology and algebraic topology in the study of datasets. By “datasets”, we almost always mean “finite metric space”.\nThese tools can be divided in some broad categories:\n\n1.2.1 Homological methods\nPersistence homology calculates the “shape” (homology groups) of a object on different scales, and compact this information into objects called “barcodes”. This barcode can be vectorized and then inserted into machine learning models.\n\n\n1.2.2 Graph reduction methods\nThe Mapper algorithm is the discrete version of the Reeb graph. It captures the geometry of a dataset with respect to a given function (called “filter”) and produce a graph of its pre-images clustered. There is also the Ball Mapper variant, which does not need a filter function and resembles the Vietoris-Rips filtration. These methods are useful to get a glimpse of the geometry (flares, holes) and areas of interest. For example: if your metric space is a dataset of measurements of patients with diabets, the Mapper graph can represent the patients and the shape of this graph can give insights about the type of diabetes one has.\n\n\n1.2.3 Clustering methods\nAlgorithms like ToMATo are clustering algorithms: we have a metric space as input, and return a partition of this dataset. Clustering is useful whenever we need to “group a set of objects in such a way that objects in the same group (called a cluster) are more similar to each other than to those in other groups (clusters)”1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#why-this-minicourse",
    "href": "index.html#why-this-minicourse",
    "title": "TDA Workshop - EBT 2024",
    "section": "1.3 Why this minicourse?",
    "text": "1.3 Why this minicourse?\nThis minicourse is a good opportunity for pure topologists to see how we can use TDA in practice. It will be even better for the applied mathematicians who can promptly recognize the tools and algorithms I am using.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#plotting",
    "href": "3d-shapes.html#plotting",
    "title": "2  3d shape classification using persistent homology",
    "section": "2.2 Plotting",
    "text": "2.2 Plotting\nHere we will see all poses together, for each class. The last pose is the reference pose.\n\n\nCode\nfunction plot_entire_class(class) \n    files = get_class_files(class)\n    fig = gl.Figure(size = (800, 1200));\n\n    for (i, file) ∈ enumerate(files)\n        p, q = divrem(i - 1, 3) .+ 1    \n        ms = read_mesh(file)\n        viz(fig[p, q], ms, title = \"a\")    \n    end\n\n    fig\nend;\n\nfunction create_gif_entire_class(class)\n    fig = plot_entire_class(class)\n\n    gl.record(fig, \"images/3d-shapes/\" * class * \".gif\", 0:31) do i\n        gl.rotate!(fig.scene, Vec3f(0, 0, 1), i * pi/16)\n    end\nend;\n\n\n\n\nCode\n# all_classes = [\n#     \"camel\", \"cat\", \"elephant\", \"face\"\n#     , \"flamingo\", \"head\", \"horse\", \"lion\"\n#     ]\n\n# @showprogress map(create_gif_entire_class, all_classes)\n\n\n\n2.2.1 Camel\n\n\n\nCamel poses\n\n\n\n\n2.2.2 Cat\n\n\n\nCat poses\n\n\n\n\n2.2.3 Elephant\n\n\n\nElephant poses\n\n\n\n\n2.2.4 Face\n\n\n\nFace poses\n\n\n\n\n2.2.5 Flamingo\n\n\n\nFlamingo poses\n\n\n\n\n2.2.6 Head\n\n\n\nHead poses\n\n\n\n\n2.2.7 Horse\n\n\n\nHorse poses\n\n\n\n\n2.2.8 Lion\n\n\n\nLion poses",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>3d shape classification using persistent homology</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#sec-3d-plotting",
    "href": "3d-shapes.html#sec-3d-plotting",
    "title": "3  3d shape classification",
    "section": "3.2 Plotting",
    "text": "3.2 Plotting\nHere we will see all poses together, for each class. The last pose is the reference pose.\n\n\nCode\nfunction plot_entire_class(class) \n    files = get_class_files(class)\n    fig = gl.Figure(size = (800, 1200));\n\n    for (i, file) ∈ enumerate(files)\n        p, q = divrem(i - 1, 3) .+ 1    \n        ms = read_mesh(file)\n        viz(fig[p, q], ms, title = \"a\")    \n    end\n\n    fig\nend;\n\nfunction create_gif_entire_class(class)\n    fig = plot_entire_class(class)\n\n    gl.record(fig, \"images/3d-shapes/\" * class * \".gif\", 0:31) do i\n        gl.rotate!(fig.scene, Vec3f(0, 0, 1), i * pi/16)\n    end\nend;\n\n\n\n\nCode\n# all_classes = [\n#     \"camel\", \"cat\", \"elephant\", \"face\"\n#     , \"flamingo\", \"head\", \"horse\", \"lion\"\n#     ]\n\n# @showprogress map(create_gif_entire_class, all_classes)\n\n\n\n3.2.1 Camel\n\n\n\nCamel poses\n\n\n\n\n3.2.2 Cat\n\n\n\nCat poses\n\n\n\n\n3.2.3 Elephant\n\n\n\nElephant poses\n\n\n\n\n3.2.4 Face\n\n\n\nFace poses\n\n\n\n\n3.2.5 Flamingo\n\n\n\nFlamingo poses\n\n\n\n\n3.2.6 Head\n\n\n\nHead poses\n\n\n\n\n3.2.7 Horse\n\n\n\nHorse poses\n\n\n\n\n3.2.8 Lion\n\n\n\nLion poses",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#a-metric-problem",
    "href": "3d-shapes.html#a-metric-problem",
    "title": "3  3d shape classification",
    "section": "3.7 A metric problem",
    "text": "3.7 A metric problem\nNow we proceed to create a dataframe that contains all we need to classify our shapes.\n\npds_df = read_pds_from_files(\"meshes/\", 0.01);\n\nfirst(pds_df, 20)\n\n20×4 DataFrame\n\n\n\nRow\nPath\nPersistence_diagram\nFile\nClass\n\n\n\nString\nArray…\nSubStrin…\nSubStrin…\n\n\n\n\n1\nmeshes/camel-poses/camel-01\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 64-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-01\ncamel\n\n\n2\nmeshes/camel-poses/camel-02\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 62-element 1-dimensional PersistenceDiagram, 5-element 2-dimensional PersistenceDiagram]\ncamel-02\ncamel\n\n\n3\nmeshes/camel-poses/camel-03\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 79-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-03\ncamel\n\n\n4\nmeshes/camel-poses/camel-04\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 75-element 1-dimensional PersistenceDiagram, 3-element 2-dimensional PersistenceDiagram]\ncamel-04\ncamel\n\n\n5\nmeshes/camel-poses/camel-05\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 68-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-05\ncamel\n\n\n6\nmeshes/camel-poses/camel-06\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 71-element 1-dimensional PersistenceDiagram, 2-element 2-dimensional PersistenceDiagram]\ncamel-06\ncamel\n\n\n7\nmeshes/camel-poses/camel-07\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 78-element 1-dimensional PersistenceDiagram, 4-element 2-dimensional PersistenceDiagram]\ncamel-07\ncamel\n\n\n8\nmeshes/camel-poses/camel-08\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 73-element 1-dimensional PersistenceDiagram, 4-element 2-dimensional PersistenceDiagram]\ncamel-08\ncamel\n\n\n9\nmeshes/camel-poses/camel-09\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 83-element 1-dimensional PersistenceDiagram, 5-element 2-dimensional PersistenceDiagram]\ncamel-09\ncamel\n\n\n10\nmeshes/camel-poses/camel-10\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 79-element 1-dimensional PersistenceDiagram, 3-element 2-dimensional PersistenceDiagram]\ncamel-10\ncamel\n\n\n11\nmeshes/camel-poses/camel-reference\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 70-element 1-dimensional PersistenceDiagram, 5-element 2-dimensional PersistenceDiagram]\ncamel-reference\ncamel\n\n\n12\nmeshes/cat-poses/cat-01\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 87-element 1-dimensional PersistenceDiagram, 11-element 2-dimensional PersistenceDiagram]\ncat-01\ncat\n\n\n13\nmeshes/cat-poses/cat-02\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 73-element 1-dimensional PersistenceDiagram, 10-element 2-dimensional PersistenceDiagram]\ncat-02\ncat\n\n\n14\nmeshes/cat-poses/cat-03\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 83-element 1-dimensional PersistenceDiagram, 15-element 2-dimensional PersistenceDiagram]\ncat-03\ncat\n\n\n15\nmeshes/cat-poses/cat-04\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 92-element 1-dimensional PersistenceDiagram, 12-element 2-dimensional PersistenceDiagram]\ncat-04\ncat\n\n\n16\nmeshes/cat-poses/cat-05\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 77-element 1-dimensional PersistenceDiagram, 6-element 2-dimensional PersistenceDiagram]\ncat-05\ncat\n\n\n17\nmeshes/cat-poses/cat-06\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 89-element 1-dimensional PersistenceDiagram, 7-element 2-dimensional PersistenceDiagram]\ncat-06\ncat\n\n\n18\nmeshes/cat-poses/cat-07\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 95-element 1-dimensional PersistenceDiagram, 11-element 2-dimensional PersistenceDiagram]\ncat-07\ncat\n\n\n19\nmeshes/cat-poses/cat-08\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 71-element 1-dimensional PersistenceDiagram, 13-element 2-dimensional PersistenceDiagram]\ncat-08\ncat\n\n\n20\nmeshes/cat-poses/cat-09\nPersistenceDiagram[350-element 0-dimensional PersistenceDiagram, 72-element 1-dimensional PersistenceDiagram, 10-element 2-dimensional PersistenceDiagram]\ncat-09\ncat\n\n\n\n\n\n\nThe dataframe looks ok! You can plot the barcodes as follows:\n\npd2 = pds_df.Persistence_diagram[1]\nplot_barcode(pd2[2:3])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we calculate the bootleneck distance between each pair of persistence diagrams. This can take some time! If you cloned the repository, you don’t need to run this piece of code.\n\npds = pds_df.Persistence_diagram\n\nn = nrow(pds_df)\nDB = zeros(n, n)\n\n@showprogress for i ∈ 1:n\n    for j ∈ i:n\n        if i == j\n            DB[i, j] = 0 \n            continue \n        end\n\n        DB[i, j] = \n            Pd.Bottleneck()(pds[i][2], pds[j][2]) + \n            Pd.Bottleneck()(pds[i][3], pds[j][3])\n\n        DB[j, i] = DB[i, j]\n    end\nend\n\nCSV.write(\"meshes/bottleneck_distance.csv\", DataFrame(DB, :auto))\n\nNotice that we defined the distance \\(DB_{i, j}\\) between two shapes \\(X_i\\) and \\(X_j\\) as\n\\[\nDB_{i, j} = d_b(\\text{dgm}_1(X_i), \\text{dgm}_1(X_j)) + d_b(\\text{dgm}_2(X_i), \\text{dgm}_2(X_j))\n\\]\nwhere \\(d_b\\) is the bottleneck distance, and \\(dgm_i\\) is the \\(i\\)-dimensional persistence diagram. Notice that we did not use the 0-dimensional persistent homology, because all shapes are connected.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#facing-the-truth",
    "href": "3d-shapes.html#facing-the-truth",
    "title": "3  3d shape classification",
    "section": "3.8 Facing the truth",
    "text": "3.8 Facing the truth\nWe read \\(DB\\) from disk, in case you did not calculate it previously\n\nDB = CSV.read(\"meshes/bottleneck_distance.csv\", DataFrame) |&gt; Matrix\nDB\n\n84×84 Matrix{Float64}:\n 0.0        0.0295622  0.0290437  …  0.0607949  0.0572987  0.0555027\n 0.0295622  0.0        0.0243571     0.0771963  0.0725624  0.0726897\n 0.0290437  0.0243571  0.0           0.0751122  0.0706953  0.07074\n 0.0250842  0.0221888  0.0246823     0.0699059  0.0653315  0.0658234\n 0.0192733  0.0247452  0.0230421     0.0647476  0.062099   0.0607826\n 0.0300337  0.0257192  0.014413   …  0.0729532  0.0680901  0.0688222\n 0.0270758  0.0372715  0.0355232     0.0541806  0.0491843  0.0458797\n 0.0239714  0.0229871  0.0240051     0.0654462  0.0644016  0.0613805\n 0.0354928  0.0229931  0.0236201     0.0807913  0.0765014  0.0759065\n 0.0282784  0.0247452  0.0209122     0.0744052  0.0719081  0.0700331\n 0.0242075  0.0255816  0.0278271  …  0.0672653  0.0677038  0.0630916\n 0.0671795  0.0780996  0.0795003     0.0520017  0.0460498  0.0740998\n 0.0622585  0.076908   0.0745496     0.0303738  0.0299614  0.0425986\n ⋮                                ⋱                        \n 0.053006   0.0704997  0.0687614     0.0305132  0.0366311  0.0263213\n 0.0479228  0.0651169  0.0636536     0.0289348  0.0406509  0.0261623\n 0.0745802  0.0753067  0.0726818     0.0587221  0.0524114  0.0815307\n 0.0505002  0.0651497  0.0599707  …  0.0282434  0.0248999  0.0497492\n 0.055084   0.0697334  0.0664574     0.0302786  0.0304893  0.0361665\n 0.0601642  0.0705143  0.066331      0.0346506  0.0309857  0.0538022\n 0.0512327  0.06873    0.0667174     0.0254585  0.0252535  0.0252038\n 0.0504608  0.0675057  0.0672269     0.0248009  0.0211124  0.0363764\n 0.061205   0.0701361  0.0729084  …  0.0441923  0.0406347  0.066897\n 0.0607949  0.0771963  0.0751122     0.0        0.0247205  0.0250417\n 0.0572987  0.0725624  0.0706953     0.0247205  0.0        0.0356727\n 0.0555027  0.0726897  0.07074       0.0250417  0.0356727  0.0\n\n\nHow can we visualize \\(DB\\)?\n\n3.8.1 Heatmap\nHeatmaps are matrices (2d arrays) where each element is colored by some value. In the ideal world, our matrix \\(DB\\) will have a square of low values for each comparison between the same class, and a higher value when comparing elements of different classes.\n\nlabels = pds_df.Class |&gt; copy\nfor i ∈ 2:length(pds_df.Class)\n    if labels[i] == pds_df.Class[i-1]\n        labels[i] = \"\"\n    end\nend\n\nlabels = (1:nrow(pds_df), labels)\n\nplot(DB, st = :heatmap, xticks = labels, yticks = labels)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nWe can see that the diagonals (intra-class comparisons) are good enough: they are dark-coloured squares, indicating small distances. But there are also black squares outside the diagonal, which means that some different classes are close to each other.\n\n\n3.8.2 Dendrograms\nDendrograms are a nice way to visualize a distance matrix. They represent the evolution of the connected components as some parameter (usually the radius of circles centered on each point) grows.\n\n\nCode\nfunction plot_hc(hc)\n    plot(\n        hc, xticks = (1:nrow(pds_df), pds_df.File[hc.order])\n        , xflip = true, xrotation = 270\n        , xtickfont = font(5, \"Roboto\")\n        )\nend;\n\n\nThe single linkage dendrogram is a mess:\n\nhclust(DB, linkage=:single, branchorder = :optimal) |&gt; plot_hc\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhead-04-grin\n\n\nhead-05-laugh\n\n\nhead-02-cry\n\n\nhead-reference\n\n\nhead-07-sad\n\n\nhead-03-fury\n\n\nhead-08-smile\n\n\nhead-09-surprise\n\n\nhead-01-anger\n\n\nhead-06-rage\n\n\nface-08-smile\n\n\nface-01-anger\n\n\nface-09-surprise\n\n\nface-07-sad\n\n\nface-reference\n\n\nface-06-rage\n\n\nelephant-03\n\n\nelephant-02\n\n\nelephant-08\n\n\nelephant-reference\n\n\nelephant-05\n\n\nelephant-06\n\n\nelephant-07\n\n\nelephant-10\n\n\nelephant-04\n\n\nelephant-01\n\n\ncat-07\n\n\nlion-01\n\n\ncat-01\n\n\nlion-07\n\n\ncat-05\n\n\nlion-04\n\n\nhorse-01\n\n\nhorse-04\n\n\nhorse-09\n\n\nhorse-02\n\n\nhorse-07\n\n\nhorse-05\n\n\nhorse-reference\n\n\nhorse-10\n\n\nhorse-08\n\n\nhorse-06\n\n\nhorse-03\n\n\nlion-reference\n\n\nlion-05\n\n\nlion-06\n\n\nlion-09\n\n\nlion-08\n\n\nlion-02\n\n\ncat-06\n\n\ncat-03\n\n\ncat-02\n\n\ncat-09\n\n\ncat-08\n\n\ncat-reference\n\n\nlion-03\n\n\ncat-04\n\n\nflam-04\n\n\nflam-05\n\n\nflam-06\n\n\nflam-03\n\n\nflam-02\n\n\nflam-08\n\n\nflam-01\n\n\nflam-10\n\n\nflam-reference\n\n\nflam-07\n\n\nflam-09\n\n\ncamel-reference\n\n\ncamel-01\n\n\ncamel-05\n\n\ncamel-08\n\n\ncamel-10\n\n\ncamel-03\n\n\ncamel-06\n\n\ncamel-09\n\n\ncamel-02\n\n\ncamel-04\n\n\ncamel-07\n\n\nelephant-09\n\n\nface-03-fury\n\n\nface-02-cry\n\n\nface-05-laugh\n\n\nface-04-grin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBut the complete linkage dendrogram shows more hope:\n\nhclust(DB, linkage = :complete, branchorder = :optimal) |&gt; plot_hc\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nflam-09\n\n\nflam-07\n\n\nflam-08\n\n\nflam-01\n\n\nflam-10\n\n\nflam-reference\n\n\nflam-03\n\n\nflam-02\n\n\nflam-06\n\n\nflam-05\n\n\nflam-04\n\n\ncamel-04\n\n\ncamel-02\n\n\ncamel-03\n\n\ncamel-06\n\n\ncamel-09\n\n\ncamel-10\n\n\ncamel-08\n\n\ncamel-reference\n\n\ncamel-05\n\n\ncamel-01\n\n\ncamel-07\n\n\nhorse-01\n\n\nhorse-04\n\n\nhorse-09\n\n\nhorse-02\n\n\nlion-reference\n\n\nlion-05\n\n\nhorse-10\n\n\nhorse-reference\n\n\nhorse-05\n\n\nhorse-07\n\n\nhorse-08\n\n\nhorse-06\n\n\nhorse-03\n\n\ncat-reference\n\n\ncat-05\n\n\nlion-06\n\n\nlion-09\n\n\nlion-08\n\n\ncat-06\n\n\ncat-04\n\n\ncat-03\n\n\ncat-02\n\n\ncat-09\n\n\ncat-08\n\n\nlion-03\n\n\nlion-02\n\n\nlion-04\n\n\nlion-01\n\n\ncat-01\n\n\nlion-07\n\n\ncat-07\n\n\nelephant-reference\n\n\nelephant-08\n\n\nelephant-02\n\n\nelephant-05\n\n\nelephant-10\n\n\nelephant-07\n\n\nelephant-06\n\n\nelephant-04\n\n\nelephant-01\n\n\nelephant-03\n\n\nelephant-09\n\n\nhead-06-rage\n\n\nhead-07-sad\n\n\nhead-reference\n\n\nhead-01-anger\n\n\nhead-09-surprise\n\n\nhead-08-smile\n\n\nhead-03-fury\n\n\nhead-02-cry\n\n\nhead-05-laugh\n\n\nhead-04-grin\n\n\nface-06-rage\n\n\nface-09-surprise\n\n\nface-01-anger\n\n\nface-reference\n\n\nface-07-sad\n\n\nface-08-smile\n\n\nface-03-fury\n\n\nface-02-cry\n\n\nface-05-laugh\n\n\nface-04-grin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is also the Ward algorithm:\n\nhclust(DB, linkage = :ward, branchorder = :optimal) |&gt; plot_hc\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nflam-09\n\n\nflam-07\n\n\nflam-06\n\n\nflam-05\n\n\nflam-04\n\n\nflam-08\n\n\nflam-01\n\n\nflam-10\n\n\nflam-reference\n\n\nflam-03\n\n\nflam-02\n\n\ncat-reference\n\n\nhorse-01\n\n\nhorse-09\n\n\nhorse-04\n\n\nhorse-03\n\n\nhorse-02\n\n\nhorse-07\n\n\nhorse-05\n\n\nhorse-reference\n\n\nhorse-10\n\n\nhorse-08\n\n\nhorse-06\n\n\nlion-08\n\n\nlion-reference\n\n\nlion-05\n\n\ncamel-07\n\n\ncamel-05\n\n\ncamel-01\n\n\ncamel-10\n\n\ncamel-08\n\n\ncamel-reference\n\n\ncamel-09\n\n\ncamel-06\n\n\ncamel-03\n\n\ncamel-02\n\n\ncamel-04\n\n\ncat-05\n\n\nlion-06\n\n\nlion-09\n\n\ncat-06\n\n\ncat-03\n\n\ncat-02\n\n\ncat-09\n\n\ncat-08\n\n\ncat-04\n\n\nlion-02\n\n\nlion-03\n\n\nlion-04\n\n\nlion-01\n\n\ncat-01\n\n\nlion-07\n\n\ncat-07\n\n\nelephant-reference\n\n\nelephant-08\n\n\nelephant-02\n\n\nelephant-05\n\n\nelephant-10\n\n\nelephant-07\n\n\nelephant-06\n\n\nelephant-04\n\n\nelephant-01\n\n\nelephant-03\n\n\nelephant-09\n\n\nhead-04-grin\n\n\nhead-05-laugh\n\n\nhead-02-cry\n\n\nhead-03-fury\n\n\nhead-08-smile\n\n\nhead-09-surprise\n\n\nhead-01-anger\n\n\nhead-reference\n\n\nhead-07-sad\n\n\nhead-06-rage\n\n\nface-06-rage\n\n\nface-09-surprise\n\n\nface-01-anger\n\n\nface-07-sad\n\n\nface-reference\n\n\nface-08-smile\n\n\nface-04-grin\n\n\nface-05-laugh\n\n\nface-02-cry\n\n\nface-03-fury\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.8.3 Accuracy\nNow let’s calculate for each shape which reference class is closer to it:\n\n\nCode\nfunction get_score_dataframe(pds_df, DB) \n  score = @select(pds_df, :Path, :File, :Class)\n\n  score.Nearest_class .= \"\"\n\n  ids_reference = findall(x -&gt; occursin(\"-reference\", x), score.Path)\n  names_reference = score.File[ids_reference]\n\n  for i ∈ 1:nrow(pds_df)\n      id = sortperm(DB[i, ids_reference])[1]\n      score.Nearest_class[i] = names_reference[id]\n  end\n\n  score.Right_class =\n      get_class_from_file.(score.Class) .== \n      get_class_from_file.(score.Nearest_class)\n\n  score\nend;\n\n\n\nscore = get_score_dataframe(pds_df, DB)\n\n84×5 DataFrame59 rows omitted\n\n\n\nRow\nPath\nFile\nClass\nNearest_class\nRight_class\n\n\n\nString\nSubStrin…\nSubStrin…\nString\nBool\n\n\n\n\n1\nmeshes/camel-poses/camel-01\ncamel-01\ncamel\ncamel-reference\ntrue\n\n\n2\nmeshes/camel-poses/camel-02\ncamel-02\ncamel\ncamel-reference\ntrue\n\n\n3\nmeshes/camel-poses/camel-03\ncamel-03\ncamel\ncamel-reference\ntrue\n\n\n4\nmeshes/camel-poses/camel-04\ncamel-04\ncamel\ncamel-reference\ntrue\n\n\n5\nmeshes/camel-poses/camel-05\ncamel-05\ncamel\ncamel-reference\ntrue\n\n\n6\nmeshes/camel-poses/camel-06\ncamel-06\ncamel\ncamel-reference\ntrue\n\n\n7\nmeshes/camel-poses/camel-07\ncamel-07\ncamel\ncamel-reference\ntrue\n\n\n8\nmeshes/camel-poses/camel-08\ncamel-08\ncamel\ncamel-reference\ntrue\n\n\n9\nmeshes/camel-poses/camel-09\ncamel-09\ncamel\ncamel-reference\ntrue\n\n\n10\nmeshes/camel-poses/camel-10\ncamel-10\ncamel\ncamel-reference\ntrue\n\n\n11\nmeshes/camel-poses/camel-reference\ncamel-reference\ncamel\ncamel-reference\ntrue\n\n\n12\nmeshes/cat-poses/cat-01\ncat-01\ncat\nelephant-reference\nfalse\n\n\n13\nmeshes/cat-poses/cat-02\ncat-02\ncat\nlion-reference\nfalse\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n73\nmeshes/horse-poses/horse-10\nhorse-10\nhorse\nhorse-reference\ntrue\n\n\n74\nmeshes/horse-poses/horse-reference\nhorse-reference\nhorse\nhorse-reference\ntrue\n\n\n75\nmeshes/lion-poses/lion-01\nlion-01\nlion\nelephant-reference\nfalse\n\n\n76\nmeshes/lion-poses/lion-02\nlion-02\nlion\nelephant-reference\nfalse\n\n\n77\nmeshes/lion-poses/lion-03\nlion-03\nlion\nlion-reference\ntrue\n\n\n78\nmeshes/lion-poses/lion-04\nlion-04\nlion\nelephant-reference\nfalse\n\n\n79\nmeshes/lion-poses/lion-05\nlion-05\nlion\nlion-reference\ntrue\n\n\n80\nmeshes/lion-poses/lion-06\nlion-06\nlion\nlion-reference\ntrue\n\n\n81\nmeshes/lion-poses/lion-07\nlion-07\nlion\nelephant-reference\nfalse\n\n\n82\nmeshes/lion-poses/lion-08\nlion-08\nlion\nlion-reference\ntrue\n\n\n83\nmeshes/lion-poses/lion-09\nlion-09\nlion\nlion-reference\ntrue\n\n\n84\nmeshes/lion-poses/lion-reference\nlion-reference\nlion\nlion-reference\ntrue\n\n\n\n\n\n\nOur accuracy was\n\nscore.Right_class |&gt; mean\n\n0.8214285714285714\n\n\nthat is: 82%. Not bad, but not excellent either!\nHere is the confusion matrix:\n\nscore_new = @rsubset score !occursin(\"ref\", :File)\nx = CM.confmat(get_class_from_file.(score_new.Nearest_class), score_new.Class)\n\n8×8 Matrix{Int64}:\n 10  0   0  0   0  0  0  0\n  0  1   0  0   0  0  0  0\n  0  2  10  0   0  0  0  4\n  0  0   0  9   0  1  0  0\n  0  0   0  0  10  0  0  0\n  0  0   0  0   0  8  0  0\n  0  0   0  0   0  0  8  0\n  0  6   0  0   0  0  2  5\n\n\n\n\n\nConfusion matrix for DB.\n\n\nSome conclusions we can take from the above analysis:\n\nCamels, elephants and faces are all correct;\nThere is one head mistaken as a face;\nThere are two mistaken horses;\nCats are confused with lions.\n\nWhy did this happen? Look back at the rotating plots in section Section 3.2: a cat and a lion are almost isometric in the geodesic sense! Thus, no tool that uses only the metric will be able to split these classes.\n\n\n3.8.4 MDS plot\nAnother last visualization technique is the multidimensional scaling plot. This method takes a distance matrix and tries to project it down to $^2) (or $^3) while distorting the distances as little as possible.\n\n\nCode\nfunction mds_plot(D, score)\n    M = fit(MDS, D; distances = true, maxoutdim = 2)\n    Y = predict(M)\n\n    score.Row = 1:length(score.Class)\n\n    dfs = @chain score begin\n        groupby(:Class)\n        collect\n    end\n\n    fig = gl.Figure();\n    ax = gl.Axis(fig[1,1])\n\n    colors = cgrad(:tableau_10, 8, categorical = true)\n\n    for (i, df) ∈ enumerate(dfs)    \n        gl.scatter!(\n            ax, Y[:, df.Row]\n            , label = df.Class[1], markersize = 15\n            , color = colors[i]\n            )\n    end\n\n    gl.axislegend();\n    fig\n\n    fig\nend\n\n\nmds_plot (generic function with 1 method)\n\n\n\nmds_plot(DB, score)\n\n\n\n\n\n\n\n\nCan we do better?\nWith only the distance matrix \\(DB\\), as we could see above, the answer is NO. We need to find more tools to compare these shapes.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#volumes",
    "href": "3d-shapes.html#volumes",
    "title": "3  3d shape classification",
    "section": "3.9 Volumes",
    "text": "3.9 Volumes\nEach mesh has a notion of volume that can be calculated with the function measure.\nWe can see below the mean volume for each class:\n\nvolumes = @showprogress map(score.Path) do f\n    ms = read_mesh(f * \".obj\")\n    measure(ms)\nend\n\ndf_volumes = DataFrame(\n    Path = score.Path, Class = score.Class, Volume = volumes\n    )\n\n@chain df_volumes begin\n    @groupby :Class\n    @combine :Mean_volume = mean(:Volume)\nend\n\n8×2 DataFrame\n\n\n\nRow\nClass\nMean_volume\n\n\n\nSubStrin…\nFloat64\n\n\n\n\n1\ncamel\n1.148\n\n\n2\ncat\n0.361138\n\n\n3\nelephant\n2.25864\n\n\n4\nface\n269.218\n\n\n5\nflam\n0.549214\n\n\n6\nhead\n1411.07\n\n\n7\nhorse\n0.978277\n\n\n8\nlion\n0.543348\n\n\n\n\n\n\nThe volume is enough to separate all the classes except lions and flamingos (which have volumes close to 0.54).\nSo let’s add this difference in volume to our original matrix \\(DB\\), and call it \\(DB2\\):\n\nn = nrow(pds_df)\nvolume_difs = zeros(n, n)\n\nfor i ∈ 1:n\n    for j ∈ i:n\n        volume_difs[i, j] = abs(df_volumes.Volume[i] - df_volumes.Volume[j])\n        volume_difs[j, i] = volume_difs[i, j]\n    end\nend\n\n# ignore differences in volume greater than maximum(DB)\nreplace!(x -&gt; x &gt; maximum(DB) ? maximum(DB) : x, volume_difs)\n\nDB2 = DB .+ volume_difs\n\n84×84 Matrix{Float64}:\n 0.0        0.0512851  0.0636892  …  0.444117   0.440621   0.438825\n 0.0512851  0.0        0.0372797     0.460519   0.455885   0.456012\n 0.0636892  0.0372797  0.0           0.458434   0.454018   0.454062\n 0.0425183  0.0264776  0.0418937     0.453228   0.448654   0.449146\n 0.0443248  0.0280738  0.0326362     0.44807    0.445421   0.444105\n 0.0666265  0.0405891  0.0163603  …  0.456276   0.451412   0.452144\n 0.0306044  0.062523   0.0736973     0.437503   0.432507   0.429202\n 0.044979   0.0237024  0.037643      0.448769   0.447724   0.444703\n 0.041761   0.0384478  0.0519975     0.464114   0.459824   0.459229\n 0.0469911  0.0277554  0.0368451     0.457728   0.45523    0.453355\n 0.0330545  0.0384575  0.0536256  …  0.450588   0.451026   0.446414\n 0.450502   0.461422   0.462823      0.200938   0.194126   0.229189\n 0.445581   0.46023    0.457872      0.204246   0.202972   0.222623\n ⋮                                ⋱                        \n 0.242155   0.237925   0.223264      0.413835   0.419953   0.409644\n 0.226422   0.221893   0.207507      0.412257   0.423973   0.409485\n 0.457903   0.458629   0.456004      0.0804654  0.0750156  0.0971215\n 0.433823   0.448472   0.443293   …  0.028584   0.0261014  0.0555611\n 0.438406   0.453056   0.44978       0.0401005  0.0411721  0.039836\n 0.443486   0.453837   0.449653      0.0422826  0.0394785  0.0552818\n 0.434555   0.452052   0.45004       0.0475827  0.0482385  0.0411755\n 0.433783   0.450828   0.450549      0.0434028  0.0405752  0.0488258\n 0.444527   0.453458   0.456231   …  0.0460268  0.0433301  0.071215\n 0.444117   0.460519   0.458434      0.0        0.0255813  0.0311942\n 0.440621   0.455885   0.454018      0.0255813  0.0        0.0426861\n 0.438825   0.456012   0.454062      0.0311942  0.0426861  0.0\n\n\nIts dendrogram is the following:\n\nhclust(DB2, linkage = :complete, branchorder = :optimal) |&gt; plot_hc\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nflam-02\n\n\nflam-reference\n\n\nflam-10\n\n\nflam-01\n\n\nflam-07\n\n\nflam-04\n\n\nflam-09\n\n\nflam-05\n\n\nflam-06\n\n\nflam-08\n\n\nflam-03\n\n\nlion-reference\n\n\nlion-05\n\n\nlion-06\n\n\nlion-08\n\n\nlion-09\n\n\nlion-02\n\n\nlion-03\n\n\nlion-04\n\n\nlion-07\n\n\nlion-01\n\n\ncat-01\n\n\ncat-07\n\n\ncat-08\n\n\ncat-09\n\n\ncat-02\n\n\ncat-03\n\n\ncat-06\n\n\ncat-reference\n\n\ncat-04\n\n\ncat-05\n\n\nhorse-03\n\n\nhorse-06\n\n\nhorse-08\n\n\nhorse-05\n\n\nhorse-02\n\n\nhorse-10\n\n\nhorse-04\n\n\nhorse-09\n\n\nhorse-reference\n\n\nhorse-07\n\n\nhorse-01\n\n\ncamel-06\n\n\ncamel-03\n\n\ncamel-05\n\n\ncamel-08\n\n\ncamel-02\n\n\ncamel-04\n\n\ncamel-10\n\n\ncamel-09\n\n\ncamel-reference\n\n\ncamel-01\n\n\ncamel-07\n\n\nelephant-reference\n\n\nelephant-10\n\n\nelephant-09\n\n\nelephant-05\n\n\nelephant-06\n\n\nelephant-04\n\n\nelephant-08\n\n\nelephant-02\n\n\nelephant-03\n\n\nelephant-01\n\n\nelephant-07\n\n\nhead-06-rage\n\n\nhead-07-sad\n\n\nhead-reference\n\n\nhead-01-anger\n\n\nhead-09-surprise\n\n\nhead-08-smile\n\n\nhead-03-fury\n\n\nhead-02-cry\n\n\nhead-05-laugh\n\n\nhead-04-grin\n\n\nface-06-rage\n\n\nface-09-surprise\n\n\nface-01-anger\n\n\nface-07-sad\n\n\nface-reference\n\n\nface-08-smile\n\n\nface-03-fury\n\n\nface-02-cry\n\n\nface-05-laugh\n\n\nface-04-grin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwhich is much better than before!\nIf again we calculate the closest reference pose to each given shape, we now get\n\nscore2 = get_score_dataframe(pds_df, DB2)\n\n84×5 DataFrame59 rows omitted\n\n\n\nRow\nPath\nFile\nClass\nNearest_class\nRight_class\n\n\n\nString\nSubStrin…\nSubStrin…\nString\nBool\n\n\n\n\n1\nmeshes/camel-poses/camel-01\ncamel-01\ncamel\ncamel-reference\ntrue\n\n\n2\nmeshes/camel-poses/camel-02\ncamel-02\ncamel\ncamel-reference\ntrue\n\n\n3\nmeshes/camel-poses/camel-03\ncamel-03\ncamel\ncamel-reference\ntrue\n\n\n4\nmeshes/camel-poses/camel-04\ncamel-04\ncamel\ncamel-reference\ntrue\n\n\n5\nmeshes/camel-poses/camel-05\ncamel-05\ncamel\ncamel-reference\ntrue\n\n\n6\nmeshes/camel-poses/camel-06\ncamel-06\ncamel\ncamel-reference\ntrue\n\n\n7\nmeshes/camel-poses/camel-07\ncamel-07\ncamel\ncamel-reference\ntrue\n\n\n8\nmeshes/camel-poses/camel-08\ncamel-08\ncamel\ncamel-reference\ntrue\n\n\n9\nmeshes/camel-poses/camel-09\ncamel-09\ncamel\ncamel-reference\ntrue\n\n\n10\nmeshes/camel-poses/camel-10\ncamel-10\ncamel\ncamel-reference\ntrue\n\n\n11\nmeshes/camel-poses/camel-reference\ncamel-reference\ncamel\ncamel-reference\ntrue\n\n\n12\nmeshes/cat-poses/cat-01\ncat-01\ncat\ncat-reference\ntrue\n\n\n13\nmeshes/cat-poses/cat-02\ncat-02\ncat\ncat-reference\ntrue\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n73\nmeshes/horse-poses/horse-10\nhorse-10\nhorse\nhorse-reference\ntrue\n\n\n74\nmeshes/horse-poses/horse-reference\nhorse-reference\nhorse\nhorse-reference\ntrue\n\n\n75\nmeshes/lion-poses/lion-01\nlion-01\nlion\nlion-reference\ntrue\n\n\n76\nmeshes/lion-poses/lion-02\nlion-02\nlion\nlion-reference\ntrue\n\n\n77\nmeshes/lion-poses/lion-03\nlion-03\nlion\nlion-reference\ntrue\n\n\n78\nmeshes/lion-poses/lion-04\nlion-04\nlion\nlion-reference\ntrue\n\n\n79\nmeshes/lion-poses/lion-05\nlion-05\nlion\nlion-reference\ntrue\n\n\n80\nmeshes/lion-poses/lion-06\nlion-06\nlion\nlion-reference\ntrue\n\n\n81\nmeshes/lion-poses/lion-07\nlion-07\nlion\nlion-reference\ntrue\n\n\n82\nmeshes/lion-poses/lion-08\nlion-08\nlion\nlion-reference\ntrue\n\n\n83\nmeshes/lion-poses/lion-09\nlion-09\nlion\nlion-reference\ntrue\n\n\n84\nmeshes/lion-poses/lion-reference\nlion-reference\nlion\nlion-reference\ntrue\n\n\n\n\n\n\n\nscore2.Right_class |&gt; mean\n\n0.9880952380952381\n\n\nnearly 100%!\nThe only misclassification can be seen with\n\n@rsubset score2 !:Right_class \n\n1×5 DataFrame\n\n\n\nRow\nPath\nFile\nClass\nNearest_class\nRight_class\n\n\n\nString\nSubStrin…\nSubStrin…\nString\nBool\n\n\n\n\n1\nmeshes/head-poses/head-05-laugh\nhead-05-laugh\nhead\nface-reference\nfalse\n\n\n\n\n\n\nwhere a head was mistaken for a face.\n\n\n\n\n\n\nSingh, Gurjeet, Facundo Mémoli, Gunnar E Carlsson, et al. 2007. “Topological Methods for the Analysis of High Dimensional Data Sets and 3d Object Recognition.” PBG@ Eurographics 2: 091–100.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  },
  {
    "objectID": "index.html#why-julia-for-topological-data-analysis",
    "href": "index.html#why-julia-for-topological-data-analysis",
    "title": "TDA Workshop - EBT 2024",
    "section": "1.1 Why Julia for topological data analysis?",
    "text": "1.1 Why Julia for topological data analysis?\nIn a world ruled by Python (and, in some areas, R), why use an exquisite and new language like Julia in this workshop? You can find some good reasons in the book Julia Data Science, but I will give some in the context of topology:\n\n1.1.1 Speed\n\n\n\n\n\n\nJulia is fast. You won’t need to use another language to make some expensive computation.\n\n\n\nLet’s say you read about a new algorithm to calculate the Vietoris-Rips. If you are a R/Python user, your algorithm won’t be written in R/Python simply because R/Python is slow. Fast code in R/Python is written in C, C++, Fortran or Rust; this is called the two language problem. Julia solves this because with enought knowledge about the compiler and the language, you will get performance nearly as good as if it was written in C. Optimize Julia code is not a trivial task, but is way easier than learning another language just to get good performance in some functions.\n\n\n\nThe famous deep learning package torch in Python has its core written mostly in C++. Python is just a “glue” interface.\n\n\n\n\n\nThe deep learning package Flux.jl is 100% written in Julia.\n\n\n\n\n1.1.2 Use other languages\n\n\n\n\n\n\nIt is easy to use another language inside Julia.\n\n\n\nEven though Julia is fast and has a robust ecosystem, Python and R have many more packages already good-to-go. You can use them easily with tools like PythonCall or RCall.\n\n\n1.1.3 Mathematical syntax\n\n\n\n\n\n\nJulia looks like mathematics and has an elegant syntax.\n\n\n\n\nLaTeX symbols\nBeing able to mix LaTeX symbols with code can make the code way more readable.\nYou can find many nice examples on BeautifulAlgorithms.jl. Below are some common Julia code:\n\n# calculate the intersection of two vectors/sets\n[1, 2] ∩ [2, 3, 4]\n\n1-element Vector{Int64}:\n 2\n\n\n\n# check if a value is in a vector/set\n1 ∉ [2, 3]\n\ntrue\n\n\n\n# define a function in one line\nf(r) = π*r^2\n\nf(3)\n\n28.274333882308138\n\n\n\n# Euler's identity\nℯ^(im * π) + 1 |&gt; round\n\n0.0 + 0.0im\n\n\n\n# calculating the pairwise-distance between points in a set\nX = [1, 2, 3, 4]\nd(x, y) = abs(x - y)\n[d(xᵢ, xⱼ) for xᵢ ∈ X, xⱼ ∈ X]\n\n4×4 Matrix{Int64}:\n 0  1  2  3\n 1  0  1  2\n 2  1  0  1\n 3  2  1  0\n\n\n\n\nBroadcasting\nEasily apply a function to all elements of a vector/set:\n\nx = [1, 2, 3, 4]\n\n# broadcast\nsin.(x)\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n# mapping\nmap(sin, x)\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n# list comprehension\n[sin(x_i) for x_i ∈ x]\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n\nPiping\nYou can compose functions in the reading order. Instead of writing:\n\nsin(cos(1))\n\n0.5143952585235492\n\n\nyou can “pipe” the functions as in:\n\n1 |&gt; cos |&gt; sin\n\n0.5143952585235492\n\n\n\n\nFunctional programming\nJulia is a functional programming language with type hierarchy, which means that we have “categories” (ie. types) and “functors” (ie. functions) mapping between the types; moreover, its polimorphism means that the functions depend on the type of its arguments.\nFor example, suppose you want to define the norm of a vector:\n\nx = [1, 2, 3]\n\n# define the norm of a Vector of Numbers\nnorm(x::Vector{&lt;:Number}) = x.^2 |&gt; sum |&gt; sqrt\nnorm(x)\n\n3.7416573867739413\n\n\nYou can also define the norm of a function \\(f\\) as the approximate integral of \\(|f|\\) on the interval \\([0, 1]\\):\n\n# norm on [0, 1]\nnorm(f::Function; step_size = 0.0001) = \n  [f(x) * step_size for x ∈ 0:step_size:1] .|&gt; \n  abs |&gt; sum\n\nsquare = x -&gt; x^2\n  \nnorm(square)\n\n0.33338333500000006\n\n\nwhich is very close to the real definite integral.\nPS: plotting is also as easy as:\n\nusing Plots;\nplot(square, 0:0.1:1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy not define the norm of a text as the amount of characters?\n\nnorm(s::AbstractString) = length(s)\nnorm(\"Hello!\")\n\n6",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "TDA Workshop - EBT 2024",
    "section": "",
    "text": "Coincidentally, I am the creator of this org. Que mundo pequeno!↩︎",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#tip-with-title",
    "href": "index.html#tip-with-title",
    "title": "TDA Workshop - EBT 2024",
    "section": "1.2 Tip with Title",
    "text": "1.2 Tip with Title\nIt is easy to use another language inside Julia.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "getting started.html",
    "href": "getting started.html",
    "title": "2  Getting started",
    "section": "",
    "text": "2.1 Persistent homology\nLet’s quickly review what is persistent homology and why it is useful.\nLet \\(M\\) be a finite metric space.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting started.html#classic-topology",
    "href": "getting started.html#classic-topology",
    "title": "3  Getting started",
    "section": "3.3 Classic topology",
    "text": "3.3 Classic topology\nLet’s start exploring some common objects in topology.\n\nusing MetricSpaces;\nimport CairoMakie as gl;\n\nimport Ripserer;\n# import PersistenceDiagrams as Pd\nimport Plots;\n\nfunction plot_barcode(bc)\n  Plots.plot(\n      Plots.plot(bc)\n      ,Ripserer.barcode(bc)\n  )\nend;\n\n\n3.3.1 Torus\n\nX = torus(1500)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 1, verbose = true, threshold = 4)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Circle\n\nX = sphere(200, dim = 2)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbv = Ripserer.ripserer(X, dim_max = 1, verbose = true)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.3 Sphere\n\nX = sphere(500, dim = 3)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 2, verbose = true)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.4 A square with a hole\n\nX = rand(gl.Point2, 1500)\nfilter!(x -&gt; (x[1]-0.5)^2 + (x[2]-0.5)^2 &gt; 0.03, X)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 1, verbose = true)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.5 Two circles\n\nX = vcat(\n    sphere(150, dim = 2)\n    ,sphere(150, dim = 2) .|&gt; x -&gt; (x .+ (1, 1))\n)\n\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 1, verbose = true)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBarsocchi, Paolo, Pietro Cassara, Daniela Giorgi, Davide Moroni, and Maria Pascali. 2018. “Computational Topology to Monitor Human Occupancy.” Proceedings 2 (January): 99. https://doi.org/10.3390/proceedings2020099.\n\n\nGhrist, Robert. 2008. “Barcodes: The Persistent Topology of Data.” Bulletin of the American Mathematical Society 45 (1): 61–75.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting started.html#persistent-homology",
    "href": "getting started.html#persistent-homology",
    "title": "2  Getting started",
    "section": "",
    "text": "2.1.1 Creating simplicial complexes\nFor each \\(\\epsilon &gt; 0\\) we create a simplicial complex \\(K_\\epsilon\\) in such a way that \\(\\epsilon_1 &lt; \\epsilon_2\\) implies \\(K_{\\epsilon} \\subseteq K_{\\epsilon'}\\).\nAs you can guess, there are several ways to “undiscretize” a finite metric space into a simplicial complex.\n\n\n\n\n\n\nOne famous construction is the Vietoris-Rips complex:\n\\[\nVR_\\epsilon(M) = \\{ [x_1, \\cdots, x_n] \\subset M \\; \\text{s.t.} \\; d(x_i, x_j) &lt; \\epsilon, \\; \\forall i, j \\}\n\\]\nthat is: if we put a ball \\(B_i\\) of radius \\(2 \\epsilon\\) around each point \\(x_i\\), then\n\\[\n[x_1, \\cdots, x_n] \\in VR_\\epsilon(M) \\Leftrightarrow \\cap B_i \\neq \\emptyset.\n\\]\n\n\n\n\n\n\nThe Vietoris-Rips filtration of a metric space (on the left of each panel). As \\(\\epsilon\\) increases, so do the amount of simplexes we have. (Barsocchi et al. 2018).\n\n\nThere are some other simplicial complex constructions like the Alpha complex or the Cech complex, but the Vietoris-Rips has a good algorithm to calculate its homology.\n\n\n2.1.2 Creating sequences of vector spaces\nApplying the homology functor with field coefficients\n\\[\nV_\\epsilon = H_n(K_\\epsilon)\n\\]\non each of the simplicial complexes\n\\[\n\\{ K_\\epsilon \\subseteq K_{\\epsilon'} \\; \\text{s.t.} \\; \\epsilon \\leq \\epsilon' \\}\n\\]\nwe obtain a sequence of vector spaces together with linear transformations\n\\[\n\\mathbb{V}(M) = \\{ V_\\epsilon \\to V_{\\epsilon'} \\; \\epsilon \\leq \\epsilon' \\}\n\\]\ncalled a persistent vector space.\n\n\n2.1.3 Simplifying\nSome very nice theorems (see Oudot 2017 for a really complete material) prove that a persistent vector space can be decomposed as a sum of interval modules, which are the fundamental blocks of persistent vector spaces. Each one of these blocks represent the birth and death of a generator. Thus, \\(\\mathbb{V}(M)\\) can summarised in two equivalent ways:\n\nas a barcode: a (multi)set of real intervals \\(\\{ [a_i, b_i) \\subset \\mathbb{R}, \\; i \\in I \\}\\).\nas a persistence diagram: a subset of real plane above the diagonal of the form \\(\\{ (a_i, b_i) \\in \\mathbb{R}^2, \\; i \\in I \\}\\).\n\nEach pair \\((a_i, b_i)\\) can be interpreted as follows: \\(a_i\\) is the value of \\(\\epsilon\\) at which a feature (i.e. a generator of \\(H_n(K_\\epsilon)\\)) was “born”, and this generator persisted until it reached \\(b_i\\). See the following image for the representation of a barcode.\nWe will use both these representations many times.\n\n\n\nA Vietoris-Rips filtration and its respective barcode. Vertical lines represent “slices” at some values of \\(\\epsilon\\). (Source: Ghrist 2008).\n\n\n\n\n2.1.4 Distances on persistence diagrams and stability\nThe bottleneck distance can be defined on the set of persitence diagrams. Intuitively, it measures the “effort” to move the points of one diagram to the points of the other OR collapsing these points to the diagonal.\nIt is important to note that points very close to the diagonal (or, equivalently, intervals very short on a barcode) can be seen as “noise” or “non relevant features”: they represent features that were born and lived for just a small time.\n\n\n\nThe bottleneck distance between two persistence diagrams (in blue and red). Source: https://gudhi.inria.fr/doc/latest/group__bottleneck__distance.html\n\n\n\n\n2.1.5 Stability of the bottleneck distance\nThis distance is much more useful because of the stability theorem: metric spaces close to each other yield barcodes close to each other:\n\\[\nd_b(\\mathbb{V}(M), \\mathbb{V}(N)) \\leq d_{GH}(M, N)\n\\]\nwhere \\(M, N\\) are finite metric spaces, \\(d_b\\) is the bottleneck distance and \\(d_{GH}\\) is the Gromov-Hausdorff distance on the set of metric spaces.\n\n\n\n\n\n\nWhy is stability useful?\n\n\n\nSuppose we have several metric spaces \\(X_1, \\ldots, X_n\\) (let’s say photos or 3d-objects) and we want to group these spaces by similarity (cats in one group, dogs in another). Calculating the Gromov-Hausdorff distance is a very expensive calculation!1. Instead, we can use the bottleneck distance of each barcode \\(\\mathbb{V}(X_i)\\) as a approximation to the geometry of \\(X_i\\).\nSo, if our barcode retains enough information about \\(X_i\\), we can use\n\\[\nd_b(\\mathbb{V}(X_i), \\mathbb{V}(X_j)) \\quad \\text{as a good approximation to} \\quad d_{GH}(X_i, X_j).\n\\]\n\n\nThe following beautiful gifs can be found at the Ripserer.jl documentation, a Julia package that implements an efficient algorithm to calculate the barcode using the Vietoris-Rips filtration.\n\n\n\nTaking random samples of the circle result in pretty similar persistent diagrams.\n\n\n\n\n\nAddin some noise to the circle does not modify so much the persistent diagram.\n\n\n\n\n\nThe persistent diagram slowly deformates itself as we add more noise to the circle.\n\n\n\n\n\nCollapsing the circle also make the 1-dimensional persistence diagram get close to the diagonal.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting started.html#footnotes",
    "href": "getting started.html#footnotes",
    "title": "2  Getting started",
    "section": "",
    "text": "see this excellent article by Matt Piekenbrock to get an idea of the complexity involved.↩︎",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting started.html#a-better-way-to-represent-barcodes",
    "href": "getting started.html#a-better-way-to-represent-barcodes",
    "title": "2  Getting started",
    "section": "2.3 A better way to represent barcodes",
    "text": "2.3 A better way to represent barcodes\nEven though the bottleneck distance is easier to calculate than the Gromov-Hausdorff distance, it is still a bit expensive for large barcodes.\nBarcodes are nice but wild objects. They have variable length. To be able to use these tools in machine learning algorithms, we need to represent them in a vector or matrix with fixed size.\nThere are several ways to do that!\n\n2.3.1 Persistence images\nPersistence images is a technique that transform a set of barcodes into nxn matrices with values from 0 to 1 (see Adams et al. 2017 for more details).\nThe idea is the following:\n\nPlot the persistence diagram;\nPlot gaussians around each point;\nPixelate them.\n\n\n\n\nThe idea behind a persistent image. Source: Adams et al. (2017).\n\n\nFor example, the two barcodes below\n\nusing PersistenceDiagrams, Plots\n\ndiag_1 = PersistenceDiagram([(0, 1), (0, 1.5), (1, 2)]);\ndiag_2 = PersistenceDiagram([(1, 2), (1, 1.5)]);\n\nimage = PersistenceImage([diag_1, diag_2])\n\nPlots.plot(\n  Plots.plot(diag_1)\n  ,Plots.plot(diag_2)\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nare transformed into these matrices (plotted as heatmaps):\n\nPlots.plot(\n  heatmap(image(diag_1))\n  ,heatmap(image(diag_2))\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdams, Henry, Tegan Emerson, Michael Kirby, Rachel Neville, Chris Peterson, Patrick Shipman, Sofya Chepushtanova, Eric Hanson, Francis Motta, and Lori Ziegelmeier. 2017. “Persistence Images: A Stable Vector Representation of Persistent Homology.” Journal of Machine Learning Research 18 (8): 1–35.\n\n\nBarsocchi, Paolo, Pietro Cassara, Daniela Giorgi, Davide Moroni, and Maria Pascali. 2018. “Computational Topology to Monitor Human Occupancy.” Proceedings 2 (January): 99. https://doi.org/10.3390/proceedings2020099.\n\n\nGhrist, Robert. 2008. “Barcodes: The Persistent Topology of Data.” Bulletin of the American Mathematical Society 45 (1): 61–75.\n\n\nOudot, Steve Y. 2017. Persistence Theory: From Quiver Representations to Data Analysis. Vol. 209. American Mathematical Soc.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "TDA Workshop - EBT 2024",
    "section": "Goals",
    "text": "Goals\nThe main goal of this minicourse is to get more people in Brazil (and elsewhere) applying TDA. There are several ways to do that:\n\nWrite a book about applied TDA. I have one in progress and need more authors!\nWrite more articles about applications, even if basic. Spread the word!\nContribute to the JuliaTDA organization on github.1\nStart analyzing real world datasets with the help of data scientists and publish some cool papers!\n\nAt the end of this minicourse, you (hopefully) will be able to:\n\nExplore Julia and its ecosystem;\nLoad and analyze datasets;\nApply some TDA techniques side-by-side with other machine learning methods;\nCreate classifiers or clusters of the original data.\n\nMy main goal with this course is to spark more interest in the applied part of TDA, and create more projects with students to code more and do more data analysis.\nRemember:\n\n2 thirds of TDA is data analysis!",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#installing-julia-and-running-code",
    "href": "index.html#installing-julia-and-running-code",
    "title": "TDA Workshop - EBT 2024",
    "section": "Installing Julia and running code",
    "text": "Installing Julia and running code\nThe best way to install Julia, VSCode and getting started is following the excellent Modern Julia Workflows.\nIn short:\n\nInstall Julia;\nInstall VSCode;\nInstall the Julia VSCode extension;\nWrite some code on VSCode;\nRun it with Shift + Enter.\n\nThat’s it!",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#installing-the-dependencies-of-this-project",
    "href": "index.html#installing-the-dependencies-of-this-project",
    "title": "TDA Workshop - EBT 2024",
    "section": "Installing the dependencies of this project",
    "text": "Installing the dependencies of this project\nIn this workshop I use several libraries with functions to deal with TDA, plots, graphs and so on. To easily install all of them, clone this repository and open it with VSCode.\nThen run any Julia code so you start the Julia REPL at the below panel. Then, type\n\n] activate .\n\nThis will install all dependencies.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Why Julia?\nIn a world ruled by Python (and, in some areas, R), why use an exquisite and new language like Julia in this workshop? You can find some good reasons in the book Julia Data Science, but I will give some in the context of topology:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#why-julia-for-topological-data-analysis",
    "href": "introduction.html#why-julia-for-topological-data-analysis",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1.1 Speed\n\n\n\n\n\n\nJulia is fast. You won’t need to use another language to make some expensive computation.\n\n\n\nLet’s say you read about a new algorithm to calculate the Vietoris-Rips. If you are a R/Python user, your algorithm won’t be written in R/Python simply because R/Python is slow. Fast code in R/Python is written in C, C++, Fortran or Rust; this is called the two language problem. Julia solves this because with enought knowledge about the compiler and the language, you will get performance nearly as good as if it was written in C. Optimize Julia code is not a trivial task, but is way easier than learning another language just to get good performance in some functions.\n\n\n\nThe famous deep learning package torch in Python has its core written mostly in C++. Python is just a “glue” interface.\n\n\n\n\n\nThe deep learning package Flux.jl is 100% written in Julia.\n\n\n\n\n2.1.2 Use other languages\n\n\n\n\n\n\nIt is easy to use another language inside Julia.\n\n\n\nEven though Julia is fast and has a robust ecosystem, Python and R have many more packages already good-to-go. You can use them easily with tools like PythonCall or RCall.\n\n\n2.1.3 Mathematical syntax\n\n\n\n\n\n\nJulia looks like mathematics and has an elegant syntax.\n\n\n\n\nLaTeX symbols\nBeing able to mix LaTeX symbols with code can make the code way more readable.\nYou can find many nice examples on BeautifulAlgorithms.jl. Below are some common Julia code:\n\n# calculate the intersection of two vectors/sets\n[1, 2] ∩ [2, 3, 4]\n\n1-element Vector{Int64}:\n 2\n\n\n\n# check if a value is in a vector/set\n1 ∉ [2, 3]\n\ntrue\n\n\n\n# define a function in one line\nf(r) = π*r^2\n\nf(3)\n\n28.274333882308138\n\n\n\n# Euler's identity\nℯ^(im * π) + 1 |&gt; round\n\n0.0 + 0.0im\n\n\n\n# calculating the pairwise-distance between points in a set\nX = [1, 2, 3, 4]\nd(x, y) = abs(x - y)\n[d(xᵢ, xⱼ) for xᵢ ∈ X, xⱼ ∈ X]\n\n4×4 Matrix{Int64}:\n 0  1  2  3\n 1  0  1  2\n 2  1  0  1\n 3  2  1  0\n\n\n\n\nBroadcasting\nEasily apply a function to all elements of a vector/set:\n\nx = [1, 2, 3, 4]\n\n# broadcast\nsin.(x)\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n# mapping\nmap(sin, x)\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n# list comprehension\n[sin(x_i) for x_i ∈ x]\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n\nPiping\nYou can compose functions in the reading order. Instead of writing:\n\nsin(cos(1))\n\n0.5143952585235492\n\n\nyou can “pipe” the functions as in:\n\n1 |&gt; cos |&gt; sin\n\n0.5143952585235492\n\n\n\n\nFunctional programming\nJulia is a functional programming language with type hierarchy, which means that we have “categories” (ie. types) and “functors” (ie. functions) mapping between the types; moreover, its polimorphism means that the functions depend on the type of its arguments.\nFor example, suppose you want to define the norm of a vector:\n\nx = [1, 2, 3]\n\n# define the norm of a Vector of Numbers\nnorm(x::Vector{&lt;:Number}) = x.^2 |&gt; sum |&gt; sqrt\nnorm(x)\n\n3.7416573867739413\n\n\nYou can also define the norm of a function \\(f\\) as the approximate integral of \\(|f|\\) on the interval \\([0, 1]\\):\n\n# norm on [0, 1]\nnorm(f::Function; step_size = 0.0001) = \n  [f(x) * step_size for x ∈ 0:step_size:1] .|&gt; \n  abs |&gt; sum\n\nsquare = x -&gt; x^2\n  \nnorm(square)\n\n0.33338333500000006\n\n\nwhich is very close to the real definite integral.\nPS: plotting is also as easy as:\n\nusing Plots;\nplot(square, 0:0.1:1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy not define the norm of a text as the amount of characters?\n\nnorm(s::AbstractString) = length(s)\nnorm(\"Hello!\")\n\n6",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#why-tda",
    "href": "introduction.html#why-tda",
    "title": "1  Introduction",
    "section": "1.2 Why TDA?",
    "text": "1.2 Why TDA?\nTopological Data Analysis is a eccentric field of mathematics that applies tools from topology and algebraic topology on the study of datasets. By “datasets”, we almost always mean “finite metric space”.\nThese tools can be divided in some broad categories:\n\n1.2.1 Homological methods\nPersistence homology calculates the “shape” (homology groups) of a object on different scales, and compact this information into objects called “barcodes”. This barcode can be vectorized and then inserted into machine learning models.\n\n\n\nThe shape of data can be summarised as a barcode.\n\n\n\n\n1.2.2 Graph reduction methods\nThe Mapper algorithm (see Singh et al. 2007) is the discrete version of the Reeb graph. It captures the geometry of a dataset with respect to a given function (called “filter”) and produce a graph of its pre-images clustered. There is also the Ball Mapper variant (see Dłotko 2019), which does not need a filter function and resembles the Vietoris-Rips filtration. These methods are useful to get a glimpse of the geometry (flares, holes) and areas of interest. For example: if your metric space is a dataset of measurements of patients with diabets, the Mapper graph can represent the patients and the shape of this graph can give insights about the type of diabetes one has.\n\n\n\nThe Mapper graph of some 3d-shapes retain some of the original geometry.\n\n\n\n\n1.2.3 Clustering methods\nAlgorithms like ToMATo (see Chazal et al. 2013) are clustering algorithms: we have a metric space as input, and return a (disjoint) partition of this dataset. Clustering is useful whenever we need to “group a set of objects in such a way that objects in the same group (called a cluster) are more similar to each other than to those in other groups (clusters)”1.\n\n\n\nToMATo is a persistence-based clustering algorithm.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#why-this-minicourse",
    "href": "introduction.html#why-this-minicourse",
    "title": "1  Introduction",
    "section": "1.3 Why this minicourse?",
    "text": "1.3 Why this minicourse?\nThis minicourse is a good opportunity for pure topologists to see how we can use TDA in practice. It will be even better for the applied mathematicians who can promptly recognize the tools and algorithms I am using.\n\n\n\n\n\n\nDłotko, Paweł. 2019. “Ball Mapper: A Shape Summary for Topological Data Analysis.” arXiv Preprint arXiv:1901.07410.\n\n\nSingh, Gurjeet, Facundo Mémoli, Gunnar E Carlsson, et al. 2007. “Topological Methods for the Analysis of High Dimensional Data Sets and 3d Object Recognition.” PBG@ Eurographics 2: 091–100.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#footnotes",
    "href": "introduction.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Cluster_analysis↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "getting started.html#some-classic-examples-in-topology",
    "href": "getting started.html#some-classic-examples-in-topology",
    "title": "2  Getting started",
    "section": "2.2 Some classic examples in topology",
    "text": "2.2 Some classic examples in topology\nLet’s start exploring some common objects in topology.\n\nusing MetricSpaces;\nimport CairoMakie as gl;\n\nimport Ripserer;\n# import PersistenceDiagrams as Pd\nimport Plots;\n\nfunction plot_barcode(bc)\n  Plots.plot(\n      Plots.plot(bc)\n      ,Ripserer.barcode(bc)\n  )\nend;\n\n\n2.2.1 Torus\n\nX = torus(1500)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 1, threshold = 4)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Circle\n\nX = sphere(300, dim = 2)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 1)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.3 Sphere\n\nX = sphere(300, dim = 3)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 2)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.4 A square with a hole\n\nX = rand(gl.Point2, 1500)\nfilter!(x -&gt; (x[1]-0.5)^2 + (x[2]-0.5)^2 &gt; 0.03, X)\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 1, verbose = true)\nplot_barcode(bc)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.5 Two circles\n\nX = vcat(\n    sphere(150, dim = 2)\n    ,sphere(150, dim = 2) .|&gt; x -&gt; (x .+ (1, 1))\n)\n\ngl.scatter(X)\n\n\n\n\n\n\n\n\n\nbc = Ripserer.ripserer(X, dim_max = 1, verbose = true)\nplot_barcode(bc)",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "introduction.html#why-julia",
    "href": "introduction.html#why-julia",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Speed\n\n\n\n\n\n\nJulia is fast. You won’t need to use another language to make some expensive computation.\n\n\n\nLet’s say you read about a new algorithm to calculate the Vietoris-Rips. If you are a R/Python user, your algorithm won’t be written in R/Python simply because R/Python is slow. Fast code in R/Python is written in C, C++, Fortran or Rust; this is called the two language problem. Julia solves this because with enought knowledge about the compiler and the language, you will get performance nearly as good as if it was written in C. Optimizing Julia code is not a trivial task, but is way easier than learning another language just to get good performance in some functions.\n\n\n\nThe famous deep learning package torch in Python has its core written mostly in C++. Python is just a “glue” interface.\n\n\n\n\n\nThe deep learning package Flux.jl is 100% written in Julia.\n\n\n\n\n1.1.2 Use other languages\n\n\n\n\n\n\nIt is easy to use another language inside Julia.\n\n\n\nEven though Julia is fast and has a robust ecosystem, Python and R have many more packages already good-to-go. You can use them easily with tools like PythonCall or RCall.\n\n\n1.1.3 Mathematical syntax\n\n\n\n\n\n\nJulia looks like mathematics and has an elegant syntax.\n\n\n\n\nLaTeX symbols\nBeing able to mix LaTeX symbols with code can make the code way more readable.\nYou can find many nice examples on BeautifulAlgorithms.jl. Below are some common Julia code:\n\n# calculate the intersection of two vectors/sets\n[1, 2] ∩ [2, 3, 4]\n\n1-element Vector{Int64}:\n 2\n\n\n\n# check if a value is in a vector/set\n1 ∉ [2, 3]\n\ntrue\n\n\n\n# define a function in one line\nf(r) = π*r^2\n\nf(3)\n\n28.274333882308138\n\n\n\n# Euler's identity\nℯ^(im * π) + 1 |&gt; round\n\n0.0 + 0.0im\n\n\n\n# calculating the pairwise-distance between points in a set\nX = [1, 2, 3, 4]\nd(x, y) = abs(x - y)\n[d(xᵢ, xⱼ) for xᵢ ∈ X, xⱼ ∈ X]\n\n4×4 Matrix{Int64}:\n 0  1  2  3\n 1  0  1  2\n 2  1  0  1\n 3  2  1  0\n\n\n\n\nBroadcasting\nEasily apply a function to all elements of a vector/set:\n\nx = [1, 2, 3, 4]\n\n# broadcast\nsin.(x)\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n# mapping\nmap(sin, x)\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n# list comprehension\n[sin(x_i) for x_i ∈ x]\n\n4-element Vector{Float64}:\n  0.8414709848078965\n  0.9092974268256817\n  0.1411200080598672\n -0.7568024953079282\n\n\n\n\nPiping\nYou can compose functions in the reading order. Instead of writing:\n\nsin(cos(1))\n\n0.5143952585235492\n\n\nyou can “pipe” the functions as in:\n\n1 |&gt; cos |&gt; sin\n\n0.5143952585235492\n\n\n\n\nFunctional programming\nJulia is a functional programming language with type hierarchy, which means that we have “categories” (ie. types) and “functors” (ie. functions) mapping between the types; moreover, its polimorphism means that the functions depend on the type of its arguments.\nFor example, suppose you want to define the norm of a vector:\n\nx = [1, 2, 3]\n\n# define the norm of a Vector of Numbers\nnorm(x::Vector{&lt;:Number}) = x.^2 |&gt; sum |&gt; sqrt\nnorm(x)\n\n3.7416573867739413\n\n\nYou can also define the norm of a function \\(f\\) as the approximate integral of \\(|f|\\) on the interval \\([0, 1]\\):\n\n# norm on [0, 1]\nnorm(f::Function; step_size = 0.0001) = \n  [f(x) * step_size for x ∈ 0:step_size:1] .|&gt; \n  abs |&gt; sum\n\nsquare = x -&gt; x^2\n  \nnorm(square)\n\n0.33338333500000006\n\n\nwhich is very close to the real definite integral.\nPS: plotting is also as easy as:\n\nusing Plots;\nplot(square, 0:0.1:1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy not define the norm of a text as the amount of characters?\n\nnorm(s::AbstractString) = length(s)\nnorm(\"Hello!\")\n\n6",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "1  Introduction",
    "section": "References",
    "text": "References\n\n\nChazal, Frédéric, Leonidas J Guibas, Steve Y Oudot, and Primoz Skraba. 2013. “Persistence-Based Clustering in Riemannian Manifolds.” Journal of the ACM (JACM) 60 (6): 1–38.\n\n\nDłotko, Paweł. 2019. “Ball Mapper: A Shape Summary for Topological Data Analysis.” arXiv Preprint arXiv:1901.07410.\n\n\nSingh, Gurjeet, Facundo Mémoli, Gunnar E Carlsson, et al. 2007. “Topological Methods for the Analysis of High Dimensional Data Sets and 3d Object Recognition.” PBG@ Eurographics 2: 091–100.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "getting started.html#references",
    "href": "getting started.html#references",
    "title": "2  Getting started",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\n\nAdams, Henry, Tegan Emerson, Michael Kirby, Rachel Neville, Chris\nPeterson, Patrick Shipman, Sofya Chepushtanova, Eric Hanson, Francis\nMotta, and Lori Ziegelmeier. 2017. “Persistence Images: A Stable\nVector Representation of Persistent Homology.” Journal of\nMachine Learning Research 18 (8): 1–35.\n\n\nBarsocchi, Paolo, Pietro Cassara, Daniela Giorgi, Davide Moroni, and\nMaria Pascali. 2018. “Computational Topology to Monitor Human\nOccupancy.” Proceedings 2 (January): 99. https://doi.org/10.3390/proceedings2020099.\n\n\nChazal, Frédéric, Leonidas J Guibas, Steve Y Oudot, and Primoz Skraba.\n2013. “Persistence-Based Clustering in Riemannian\nManifolds.” Journal of the ACM (JACM) 60 (6): 1–38.\n\n\nDłotko, Paweł. 2019. “Ball Mapper: A Shape Summary for Topological\nData Analysis.” arXiv Preprint arXiv:1901.07410.\n\n\nGhrist, Robert. 2008. “Barcodes: The Persistent Topology of\nData.” Bulletin of the American Mathematical Society 45\n(1): 61–75.\n\n\nOudot, Steve Y. 2017. Persistence Theory: From Quiver\nRepresentations to Data Analysis. Vol. 209. American Mathematical\nSoc.\n\n\nSingh, Gurjeet, Facundo Mémoli, Gunnar E Carlsson, et al. 2007.\n“Topological Methods for the Analysis of High Dimensional Data\nSets and 3d Object Recognition.” PBG@ Eurographics 2:\n091–100.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Adams, Henry, Tegan Emerson, Michael Kirby, Rachel Neville, Chris\nPeterson, Patrick Shipman, Sofya Chepushtanova, Eric Hanson, Francis\nMotta, and Lori Ziegelmeier. 2017. “Persistence Images: A Stable\nVector Representation of Persistent Homology.” Journal of\nMachine Learning Research 18 (8): 1–35.\n\n\nBarsocchi, Paolo, Pietro Cassara, Daniela Giorgi, Davide Moroni, and\nMaria Pascali. 2018. “Computational Topology to Monitor Human\nOccupancy.” Proceedings 2 (January): 99. https://doi.org/10.3390/proceedings2020099.\n\n\nChazal, Frédéric, Leonidas J Guibas, Steve Y Oudot, and Primoz Skraba.\n2013. “Persistence-Based Clustering in Riemannian\nManifolds.” Journal of the ACM (JACM) 60 (6): 1–38.\n\n\nDłotko, Paweł. 2019. “Ball Mapper: A Shape Summary for Topological\nData Analysis.” arXiv Preprint arXiv:1901.07410.\n\n\nGhrist, Robert. 2008. “Barcodes: The Persistent Topology of\nData.” Bulletin of the American Mathematical Society 45\n(1): 61–75.\n\n\nOudot, Steve Y. 2017. Persistence Theory: From Quiver\nRepresentations to Data Analysis. Vol. 209. American Mathematical\nSoc.\n\n\nSingh, Gurjeet, Facundo Mémoli, Gunnar E Carlsson, et al. 2007.\n“Topological Methods for the Analysis of High Dimensional Data\nSets and 3d Object Recognition.” PBG@ Eurographics 2:\n091–100.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "digits.html",
    "href": "digits.html",
    "title": "4  Classifying hand-written digits",
    "section": "",
    "text": "4.1 Loading packages\nimport MLDatasets\nusing Images, Makie, CairoMakie\nusing Distances\nusing Ripserer, PersistenceDiagrams\nusing StatsBase: mean\nimport Plots;\nusing DataFrames, FreqTables, PrettyTables\nusing Flux, ProgressMeter",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "digits.html#the-dataset",
    "href": "digits.html#the-dataset",
    "title": "4  Classifying hand-written digits",
    "section": "4.2 The dataset",
    "text": "4.2 The dataset\nMNIST is a dataset consisting of 70.000 hand-written digits. Each digit is a 28x28 grayscale image, that is: a 28x28 matrix of values from 0 to 1. To get this dataset, run\n\nn_train = 10_000\nmnist_digits, mnist_labels = MLDatasets.MNIST(split=:train)[:];\nmnist_digits = mnist_digits[:, :, 1:n_train]\nmnist_labels = mnist_labels[1:n_train];\n\nIf the console asks you to download some data, just press y.\nNotice that we only get the first n_train images so this notebook doesn’t take too much time to run. You can increase n_train to 60000 if you like to live dangerously and have enough RAM memory.\nNext, we transpose the digits and save them in a vector\n\nfigs = [mnist_digits[:, :, i]' |&gt; Matrix for i ∈ 1:size(mnist_digits)[3]];\n\nThe first digit, for example, is the following matrix:\n\nfigs[1]\n\n28×28 Matrix{Float32}:\n 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0       …  0.498039  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.25098   0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n ⋮                             ⋮         ⋱                 ⋮         \n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.215686  0.67451      0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.533333  0.992157     0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n\n\nWe can see a mosaic with the first 10^2 digits\n\nn = 10\nfigs_plot = [fig .|&gt; Gray for fig in figs[1:n^2]]\nmosaicview(figs_plot, nrow = n, rowmajor = true)",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "digits.html#a-geometrical-thinking",
    "href": "digits.html#a-geometrical-thinking",
    "title": "4  Classifying hand-written digits",
    "section": "4.3 A geometrical thinking",
    "text": "4.3 A geometrical thinking\nWhat topological tools can be useful to distinguish between different digits?\nPersistence homology with Vietoris-Rips filtration won’t be of much help: all digits are connected, so the 0-persistence is useless; for the 1-dimensional persistence,\n\n1, 3, 5, 7 do not contain holes;\n2 and 4 sometimes contain one hole (depending on the way you write it);\n0, 6, 9 contain one hole each;\n8 contains two holes.\n\nWhat if we starting chopping the digits with sublevels of some functions?\nIn Chapter 1 we talked about the Vietoris-Rips filtration to obtain a barcode. But there is also another useful way to create barcodes from data: sublevel filtrations.\n\n\n\nA sublevel filtration uses a real function to slice inverse images and create a sequence of sets, one contained in the another. (Source: Chazal, n.d.).\n\n\nThe excentricity function is able to highlight edges. Doing a sublevel filtration with the excentricity function will permit us to separate digits by the amount of edges they have. So 1 and 3 and 7, for example, will have different persistence diagrams.\n\n4.3.1 From square matrices to points in the plane\nIn order to calculate the excentricity, we need to convert the “image digits” (28x28 matrices) to points in \\(\\mathbb{R}^2\\) (matrices with 2 columns, one for each dimension, which we will call pointclouds). A simple function can do that:\n\nfunction img_to_points(img, threshold = 0.3)\n    ids = findall(x -&gt; x &gt;= threshold, img)\n    pts = getindex.(ids, [1 2])\nend;\n\nNotice that we had to define a threshold so we only get white pixels.\nLet’s also define a function to plot a digit:\n\nfunction plot_digit(fig, values = :black)\n    pt = img_to_points(fig)\n    f = Figure();\n    ax = Makie.Axis(f[1, 1], autolimitaspect = 1, yreversed = true)\n    scatter!(ax, pt[:, 2], pt[:, 1]; markersize = 40, marker = :rect, color = values)\n    if values isa Vector{&lt;:Real}\n        Colorbar(f[1, 2])\n    end\n    f\nend;\n\nWe can see that it works as expected\n\nfig = figs[3]\nheatmap(fig)\n\n\n\n\n\n\n\n\nbut the image is flipped. This is easily fixed:\n\nheatmap(fig |&gt; rotr90)\n\n\n\n\n\n\n\n\n\n\n4.3.2 Excentricity\nThe excentricity of a metric space \\((X, d)\\) is a measure of how far a point is from the “center”. It is defined as follows for each \\(x \\in X\\):\n\\[\ne(x) = \\sum_{y \\in X} \\frac{d(x, y)}{N}\n\\]\nwhere \\(N\\) is the amount of points of \\(X\\).\nDefine a function that takes a digit in \\(\\mathbb{R}^2\\) and return the excentricity as an 28x28 image\n\nfunction excentricity(fig)\n    pt = img_to_points(fig)\n    dists = pairwise(Euclidean(), pt')\n    excentricity = [mean(c) for c ∈ eachcol(dists)]\n    exc_matrix = zeros(28, 28)\n\n    for (row, (i, j)) ∈ enumerate(eachrow(pt))\n        exc_matrix[i, j] = excentricity[row]\n    end\n\n    return exc_matrix\nend;\n\nWe store all the excentricities in the excs vector\n\nexcs = excentricity.(figs);\n\nand plot a digit with it’s corresponding excentricity\n\ni = 5\nfig = figs[i]\nexc = excs[i]\nheatmap(exc |&gt; rotr90)\n\n\n\n\n\n\n\n\nLooks good! Time to chop it!\n\n\n4.3.3 Persistence images\nNow we calculate all the persistence diagrams using sublevel filtration. This can take some seconds. Julia is incredibly fast, but does not perform miracles (yet!).\n\npds = map(excs) do ex\n    m = maximum(ex)\n    ex = m .- ex\n    ripserer(Cubical(ex), cutoff = 0.5)\nend;\n\nWe check the first one\n\npd = pds[i]\npd |&gt; barcode\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare it with the corresponding heatmap above. There are 3 main edges (and one really small one). It seems ok!\nWe can see the “step-by-step” creation of these connected components in the following mosaic.\n\nr = range(minimum(exc), maximum(exc), length = 25) |&gt; reverse\nfigs_filtration = map(r) do v\n    replace(x -&gt; x ≤ v ? 0 : 1, exc) .|&gt; Gray\nend\n\nmosaicview(figs_filtration..., rowmajor = true, nrow = 5, npad = 20)\n\n\n\n\nNow we create the persistence images of all these barcodes in dimension 0 and 1. We pass the entire collection of barcodes to the PersistenceImage function, and it will ensure that all of them are comparable (ie. are on the same grid).\n\npds_0 = pds .|&gt; first\npds_1 = pds .|&gt; last\nimgs_0 = PersistenceImage(pds_0; sigma = 1, size = 8)\nimgs_1 = PersistenceImage(pds_1; sigma = 1, size = 8);\n\nThe persistence images look ok too:\n\nPlots.plot(\n    barcode(pds[i])\n    , Plots.plot(pds[i]; persistence = true)\n    , Plots.heatmap(imgs_0(pds[i][1]); aspect_ratio=1)\n    ,  Plots.heatmap(imgs_1(pds[i][2]); aspect_ratio=1)\n    , layout = (2, 2)\n    )\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\nTop left: the barcode of a digit with respect to sublevels using the excentricity function. Top right: the corresponding persistence diagram. Bottom: 0 and 1 dimensional persistence images. They create a pixelated view of the persistence diagram, using a gaussian blur.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "digits.html#fitting-a-model",
    "href": "digits.html#fitting-a-model",
    "title": "4  Classifying hand-written digits",
    "section": "4.4 Fitting a model",
    "text": "4.4 Fitting a model\nIn order to use these persistence images in a machine learning model, we first need to vectorize them, ie, transform them into a vector. Machine learning models love vectors! The easist way is to just concatenate the persistence images as follows:\n\nfunction concatenate_pds(imgs_0, pds_0, imgs_1, pds_1)\n    persims = [\n        [vec(imgs_0(pds_0[i])); vec(imgs_1(pds_1[i])) ] for i in 1:length(pds)\n        ]\n\n    X = reduce(hcat, persims)'\n    X\nend\n\nX = concatenate_pds(imgs_0, pds_0, imgs_1, pds_1)\ny = mnist_labels .|&gt; string;\n\nWe can see that X is a matrix with 10000 rows (the amount of digits) and 128 columns (the persistence images concatenated).\nIt was also important to convert the mnist_labels to strings, because we want to classify the digits (and not do a regression on them).\nWe now have a vector for each image. What can we do? We need a model that takes a large vector of numbers and try to predict the digit. Neural networks are excellent in finding non-linear relations on vectors. Let’s try one!\nCreate the layers\n\nfunction nn_model(X)\n  model = Chain(\n      Dense(size(X)[2] =&gt; 64)\n      ,Dense(64 =&gt; 10)\n  )\nend\n\nmodel = nn_model(X)\n\n\nChain(\n  Dense(128 =&gt; 64),                     # 8_256 parameters\n  Dense(64 =&gt; 10),                      # 650 parameters\n)                   # Total: 4 arrays, 8_906 parameters, 35.039 KiB.\n\n\n\nthe loader\n\ntarget = Flux.onehotbatch(y, 0:9 .|&gt; string)\nloader = Flux.DataLoader((X' .|&gt; Float32, target), batchsize=32, shuffle=true);\n\nthe optimiser\n\noptim = Flux.setup(Flux.Adam(0.01), model);\n\nand train it\n\n@showprogress for epoch in 1:100\n    Flux.train!(model, loader, optim) do m, x, y\n        y_hat = m(x)\n        Flux.logitcrossentropy(y_hat, y)\n    end\nend;\n\nThe predictions can be made with\n\npred_y = model(X' .|&gt; Float32)\npred_y = Flux.onecold(pred_y, 0:9 .|&gt; string);\n\nAnd the accuracy\n\naccuracy = sum(pred_y .== y) / length(y)\naccuracy = round(accuracy * 100, digits = 2)\nprintln(\"The accuracy on the train set was $accuracy %!\")\n\nThe accuracy on the train set was 70.79 %!\n\n\nNot bad, taking into account that we only used the excentricity sublevel filtration.\nThe confusion matrix is the following:\n\ntbl = freqtable(y, pred_y)\n\n10×10 Named Matrix{Int64}\nDim1 ╲ Dim2 │    0     1     2     3     4     5     6     7     8     9\n────────────┼───────────────────────────────────────────────────────────\n0           │  920     0    21    16     2     6    13     2    13     8\n1           │    1  1078     7    11     4     5     0    21     0     0\n2           │   19    12   522    83   100    27    19    72   107    30\n3           │    6    36    37   757    18    52     7   100    13     6\n4           │    0     2    77    13   751     9     2   113     6     7\n5           │   13    40    46   310    11   283    14   118     6    22\n6           │   19     2    15     5     7     3   664    79     8   212\n7           │    2    41    35    49   126    20    42   753     2     0\n8           │   13     2    69    10    21     1     4     9   787    28\n9           │   13     1    29    17    14     6   219   102    13   564\n\n\nCalculating the proportion of prediction for each digit, we get\n\nround2(x) = round(100*x, digits = 1)\n\nfunction prop_table(y1, y2)\n    tbl = freqtable(y1, y2)\n    tbl_prop = prop(tbl, margins = 1) .|&gt; round2\n    tbl_prop\nend\n\ntbl_p = prop_table(y, pred_y)\n\n10×10 Named Matrix{Float64}\nDim1 ╲ Dim2 │    0     1     2     3     4     5     6     7     8     9\n────────────┼───────────────────────────────────────────────────────────\n0           │ 91.9   0.0   2.1   1.6   0.2   0.6   1.3   0.2   1.3   0.8\n1           │  0.1  95.7   0.6   1.0   0.4   0.4   0.0   1.9   0.0   0.0\n2           │  1.9   1.2  52.7   8.4  10.1   2.7   1.9   7.3  10.8   3.0\n3           │  0.6   3.5   3.6  73.4   1.7   5.0   0.7   9.7   1.3   0.6\n4           │  0.0   0.2   7.9   1.3  76.6   0.9   0.2  11.5   0.6   0.7\n5           │  1.5   4.6   5.3  35.9   1.3  32.8   1.6  13.7   0.7   2.5\n6           │  1.9   0.2   1.5   0.5   0.7   0.3  65.5   7.8   0.8  20.9\n7           │  0.2   3.8   3.3   4.6  11.8   1.9   3.9  70.4   0.2   0.0\n8           │  1.4   0.2   7.3   1.1   2.2   0.1   0.4   1.0  83.4   3.0\n9           │  1.3   0.1   3.0   1.7   1.4   0.6  22.4  10.4   1.3  57.7\n\n\nWe see that the biggest errors are the following:\n\nfunction top_errors(tbl_p)\n    df = DataFrame(\n        Digit = Integer[]\n        , Prediction = Integer[]\n        , Percentage = Float64[]\n        )\n    \n    for i = eachindex(IndexCartesian(), tbl_p)\n        push!(df, (i[1]-1, i[2]-1, tbl_p[i]))    \n    end   \n   \n    filter!(row -&gt; row.Digit != row.Prediction, df)\n    sort!(df, :Percentage, rev = true)\n    df[1:10, :]    \nend\n\ndf_errors = top_errors(tbl_p)\ndf_errors |&gt; pretty_table\n\n┌─────────┬────────────┬────────────┐\n│   Digit │ Prediction │ Percentage │\n│ Integer │    Integer │    Float64 │\n├─────────┼────────────┼────────────┤\n│       5 │          3 │       35.9 │\n│       9 │          6 │       22.4 │\n│       6 │          9 │       20.9 │\n│       5 │          7 │       13.7 │\n│       7 │          4 │       11.8 │\n│       4 │          7 │       11.5 │\n│       2 │          8 │       10.8 │\n│       9 │          7 │       10.4 │\n│       2 │          4 │       10.1 │\n│       3 │          7 │        9.7 │\n└─────────┴────────────┴────────────┘\n\n\n\n4.4.1 The perils of isometric spaces\nHow to separate “6” and “9”? They are isometric! For some people, “2” and “5” are also isometric (just mirror on the x-axis). Functions that only “see” the metric1 (like the excentricity) will never be able to separate these digits. In digits, the position of the features is important, so let’s add more slicing filtrations to our arsenal.\nTo avoid writing all the above code-blocks again, we encapsulate the whole process into a function\n\nfunction whole_process(\n    mnist_digits, mnist_labels, f\n    ; imgs_0 = nothing, imgs_1 = nothing\n    , dim_max = 1, sigma = 1, size_persistence_image = 8\n    )\n    figs = [mnist_digits[:, :, i]' |&gt; Matrix for i ∈ 1:size(mnist_digits)[3]]\n\n    excs = f.(figs);\n\n    pds = map(excs) do ex\n        m = maximum(ex)\n        ex = m .- ex\n        ripserer(Cubical(ex), cutoff = 0.5, dim_max = dim_max)\n    end;\n\n    pds_0 = pds .|&gt; first\n    pds_1 = pds .|&gt; last\n\n    if isnothing(imgs_0) \n        imgs_0 = PersistenceImage(pds_0; sigma = sigma, size = size_persistence_image) \n    end\n    if isnothing(imgs_1) \n        imgs_1 = PersistenceImage(pds_1; sigma = sigma, size = size_persistence_image) \n    end\n\n    persims = [\n    [vec(imgs_0(pds_0[i])); vec(imgs_1(pds_1[i])) ] for i in eachindex(pds)\n    ]\n\n    X = reduce(hcat, persims)'\n    y = mnist_labels .|&gt; string\n\n    return X, y, pds_0, pds_1, imgs_0, imgs_1\nend;\n\nWe now create the sideways filtrations: from the side and from above.\n\nset_value(x, threshold = 0.5, value = 0) = x ≥ threshold ? value : 0\n\nfunction filtration_sideways(fig; axis = 1, invert = false)\n\n  fig2 = copy(fig)\n  if axis == 2 fig2 = fig2' |&gt; Matrix end\n\n  for i ∈ 1:28\n    if invert k = 29 - i else k = i end\n    fig2[i, :] .= set_value.(fig2[i, :], 0.5, k)\n  end\n\n  fig2\n\nend;\n\nand calculate all 4 persistence diagrams. Warning: this can take a few seconds if you are using 60000 digits!\n\nfs = [\n    x -&gt; filtration_sideways(x, axis = 1, invert = false)\n    ,x -&gt; filtration_sideways(x, axis = 2, invert = false)\n    ,x -&gt; filtration_sideways(x, axis = 1, invert = true)\n    ,x -&gt; filtration_sideways(x, axis = 2, invert = true)\n]\n\nret = @showprogress map(fs) do f\n    whole_process(\n        mnist_digits, mnist_labels, f\n        ,size_persistence_image = 8\n    )\nend;\n\nWe concatenate all the vectors\n\nX_list = ret .|&gt; first\nX_all = hcat(X, X_list...);\n\nand try again with a new model:\n\nmodel = nn_model(X_all)\n\ntarget = Flux.onehotbatch(y, 0:9 .|&gt; string)\nloader = Flux.DataLoader((X_all' .|&gt; Float32, target), batchsize=64, shuffle=true);\n\noptim = Flux.setup(Flux.Adam(0.01), model)\n\n@showprogress for epoch in 1:50\n    Flux.train!(model, loader, optim) do m, x, y\n        y_hat = m(x)\n        Flux.logitcrossentropy(y_hat, y)\n    end\nend;\n\nNow we have\n\npred_y = model(X_all' .|&gt; Float32)\npred_y = Flux.onecold(pred_y, 0:9 .|&gt; string)\n\naccuracy = sum(pred_y .== y) / length(y)\naccuracy = round(accuracy * 100, digits = 2)\nprintln(\"The accuracy on the train set was $accuracy %!\")\n\nThe accuracy on the train set was 95.15 %!\n\n\nwhich is certainly an improvement!\nThe proportional confusion matrix is\n\nprop_table(y, pred_y)\n\n10×10 Named Matrix{Float64}\nDim1 ╲ Dim2 │    0     1     2     3     4     5     6     7     8     9\n────────────┼───────────────────────────────────────────────────────────\n0           │ 99.6   0.0   0.1   0.0   0.1   0.1   0.1   0.0   0.0   0.0\n1           │  0.0  97.6   0.4   0.5   0.1   0.3   0.0   1.2   0.0   0.0\n2           │  0.0   1.3  82.2   1.8   0.1   9.3   0.5   4.6   0.0   0.1\n3           │  0.0   0.6   0.6  91.3   0.1   2.0   0.0   5.3   0.0   0.1\n4           │  0.0   0.2   0.0   0.0  98.4   0.0   0.3   0.5   0.1   0.5\n5           │  0.0   1.2   1.5   1.4   0.1  94.2   0.8   0.5   0.0   0.3\n6           │  0.0   0.2   0.2   0.0   0.1   0.5  98.9   0.1   0.0   0.0\n7           │  0.0   2.2   0.4   0.7   0.1   0.4   0.2  96.0   0.0   0.1\n8           │  0.0   0.2   0.7   0.1   1.1   0.3   0.1   0.3  95.0   2.1\n9           │  0.0   0.1   0.0   0.0   0.5   0.2   0.2   1.1   0.0  97.9",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "digits.html#learning-from-your-mistakes",
    "href": "digits.html#learning-from-your-mistakes",
    "title": "4  Classifying hand-written digits",
    "section": "4.5 Learning from your mistakes",
    "text": "4.5 Learning from your mistakes\nLet’s explore a bit where the model is making mistakes. Collect all the errors\n\nerrors = findall(pred_y .!= y);\n\nand plot the first 3\n\ni = errors[1]\nprintln(\"The model predicted a $(pred_y[i]) but it was a $(y[i])\")\nplot_digit(figs[i])\n\nThe model predicted a 2 but it was a 1\n\n\n\n\n\n\n\n\n\n\ni = errors[2]\nprintln(\"The model predicted a $(pred_y[i]) but it was a $(y[i])\")\nplot_digit(figs[i])\n\nThe model predicted a 5 but it was a 2\n\n\n\n\n\n\n\n\n\n\ni = errors[3]\nprintln(\"The model predicted a $(pred_y[i]) but it was a $(y[i])\")\nplot_digit(figs[i])\n\nThe model predicted a 5 but it was a 2\n\n\n\n\n\n\n\n\n\nWe can make a mosaic with the first 100 errors\n\nn = 10\nfigs_plot = [figs[i] .|&gt; Gray for i in errors[1:n^2]]\nmosaicview(figs_plot, nrow = n, rowmajor = true)\n\n\n\n\nMany of these digits are really ugly! This makes them hard to classify with our sublevel filtrations. Some other functions could be explored.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "digits.html#getting-new-data",
    "href": "digits.html#getting-new-data",
    "title": "4  Classifying hand-written digits",
    "section": "4.6 Getting new data",
    "text": "4.6 Getting new data\nNow we want to see if our model really learned something, or if it just repeated what he saw in the training data. To check data, we need to get new data and calculate the accuracy of the same model on this new data.\n\nn_test = 5_000\nnew_mnist_digits, new_mnist_labels = MLDatasets.MNIST(split=:test)[:];\nnew_mnist_digits = new_mnist_digits[:, :, 1:n_test]\nnew_mnist_labels = new_mnist_labels[1:n_test];\n\nand obtaning X and y to feed the model\n\nfs = [\n    x -&gt; excentricity(x)\n    ,x -&gt; filtration_sideways(x, axis = 1, invert = false)\n    ,x -&gt; filtration_sideways(x, axis = 2, invert = false)\n    ,x -&gt; filtration_sideways(x, axis = 1, invert = true)\n    ,x -&gt; filtration_sideways(x, axis = 2, invert = true)\n]\n\nret = @showprogress map(fs) do f\n    whole_process(\n        new_mnist_digits, new_mnist_labels, f\n        ,size_persistence_image = 8\n    )\nend;\n\nDefine our new X and y\n\nnew_X = ret .|&gt; first\nnew_X = hcat(new_X...)\nnew_y = ret[1][2]\n\nnew_pred_y = model(new_X' .|&gt; Float32)\nnew_pred_y = Flux.onecold(new_pred_y, 0:9 .|&gt; string);\n\nand calculate the accuracy:\n\naccuracy = sum(new_pred_y .== new_y) / length(new_y)\naccuracy = round(accuracy * 100, digits = 2)\nprintln(\"The accuracy on the test data was $accuracy %!\")\n\nThe accuracy on the test data was 86.82 %!\n\n\nA bit less than the training set, but not so bad.\nLet’s check the confusion matrix\n\ntbl = prop_table(new_y, new_pred_y)\n\n10×10 Named Matrix{Float64}\nDim1 ╲ Dim2 │    0     1     2     3     4     5     6     7     8     9\n────────────┼───────────────────────────────────────────────────────────\n0           │ 95.4   0.0   0.9   0.2   0.7   0.2   0.7   0.7   0.4   0.9\n1           │  0.2  96.3   0.9   0.4   0.4   0.4   0.2   1.4   0.0   0.0\n2           │  0.9   0.8  74.0   3.8   1.1  13.2   1.5   3.6   0.9   0.2\n3           │  0.2   1.2   4.6  79.0   0.0   5.4   0.2   8.8   0.4   0.2\n4           │  0.0   1.0   1.0   0.2  93.8   0.8   0.2   0.8   0.4   1.8\n5           │  0.4   1.5   9.4   4.4   1.5  79.2   0.4   1.5   1.1   0.4\n6           │  1.5   0.6   2.6   0.2   1.3   2.8  87.4   0.0   3.2   0.2\n7           │  0.2   3.3   2.1   2.1   4.9   1.4   0.0  85.4   0.0   0.6\n8           │  1.2   0.2   5.1   0.2   0.4   0.6   0.0   0.0  88.5   3.7\n9           │  0.2   0.8   0.6   0.0   4.0   0.6   0.4   2.9   1.9  88.7",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "digits.html#moral-of-the-story",
    "href": "digits.html#moral-of-the-story",
    "title": "4  Classifying hand-written digits",
    "section": "4.7 Moral of the story",
    "text": "4.7 Moral of the story\nEven though we used heavy machinery from topology, at the end our persistence images were vectors that indicated the birth and death of connected components and holes. Apart from that, the only machine learning algorithm we used was a simple dense neural network to fit these vectors to the correct labels in a non-linear way.\nState-of-art machine learning models on the MNIST dataset usually can get more than 99% of accuracy, but they use some complicated neural networks with many layers, and the output prediction are hard to explain. These methods, however, are not excludent of each other: we can use the persistence images (and any other vectorized output from TDA) together with other algorithms.\n\n4.7.1 Exercise left to the reader\nA curious reader can try to add more features to the input of the neural network, for example the amount of points, the mean excentricity, the and so on. Addin more features can improve the accuracy of the neural network.\nIf you are brave enough and want to get in the world of deep learning, a good exercise is to create a neural network with two parallel inputs - one for the digits images, followed by convolutional layers - other for the vector of persistence images, followed by dense layers can achieve a better result than the convolutional alone.\n\n\n\n\n\n\nChazal, Frédéric. n.d. “A Brief Introduction to Persistent Homology.” Https://Gdr-Gdm.univ-Lr.fr/Ihp-Maths-Meca/Materials/Chazal_ihp_Nov2021.pdf.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "digits.html#footnotes",
    "href": "digits.html#footnotes",
    "title": "4  Classifying hand-written digits",
    "section": "",
    "text": "ie. are invariant under isometries↩︎",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classifying hand-written digits</span>"
    ]
  },
  {
    "objectID": "3d-shapes.html#the-dataset",
    "href": "3d-shapes.html#the-dataset",
    "title": "3  3d shape classification",
    "section": "",
    "text": "In (Singh et al. 2007) the authors used two different methods to cluster the different 3d shapes: an approximation to the Gromov Hausdorff distance, and a distance on the Mapper graph of each shape. Here in this chapter, we are going to use persistent homology.",
    "crumbs": [
      "Part 1: Persistence homology",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>3d shape classification</span>"
    ]
  }
]