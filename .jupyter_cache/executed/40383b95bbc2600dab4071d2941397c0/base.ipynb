{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd00ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IJulia\n",
    "\n",
    "# The julia kernel has built in support for Revise.jl, so this is the \n",
    "# recommended approach for long-running sessions:\n",
    "# https://github.com/JuliaLang/IJulia.jl/blob/9b10fa9b879574bbf720f5285029e07758e50a5e/src/kernel.jl#L46-L51\n",
    "\n",
    "# Users should enable revise within .julia/config/startup_ijulia.jl:\n",
    "# https://timholy.github.io/Revise.jl/stable/config/#Using-Revise-automatically-within-Jupyter/IJulia-1\n",
    "\n",
    "# clear console history\n",
    "IJulia.clear_history()\n",
    "\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = :retina\n",
    "fig_dpi = 96\n",
    "\n",
    "# no retina format type, use svg for high quality type/marks\n",
    "if fig_format == :retina\n",
    "  fig_format = :svg\n",
    "elseif fig_format == :pdf\n",
    "  fig_dpi = 96\n",
    "  # Enable PDF support for IJulia\n",
    "  IJulia.register_mime(MIME(\"application/pdf\"))\n",
    "end\n",
    "\n",
    "# convert inches to pixels\n",
    "fig_width = fig_width * fig_dpi\n",
    "fig_height = fig_height * fig_dpi\n",
    "\n",
    "# Intialize Plots w/ default fig width/height\n",
    "try\n",
    "  import Plots\n",
    "\n",
    "  # Plots.jl doesn't support PDF output for versions < 1.28.1\n",
    "  # so use png (if the DPI remains the default of 300 then set to 96)\n",
    "  if (Plots._current_plots_version < v\"1.28.1\") & (fig_format == :pdf)\n",
    "    Plots.gr(size=(fig_width, fig_height), fmt = :png, dpi = fig_dpi)\n",
    "  else\n",
    "    Plots.gr(size=(fig_width, fig_height), fmt = fig_format, dpi = fig_dpi)\n",
    "  end\n",
    "catch e\n",
    "  # @warn \"Plots init\" exception=(e, catch_backtrace())\n",
    "end\n",
    "\n",
    "# Initialize CairoMakie with default fig width/height\n",
    "try\n",
    "  import CairoMakie\n",
    "\n",
    "  # CairoMakie's display() in PDF format opens an interactive window\n",
    "  # instead of saving to the ipynb file, so we don't do that.\n",
    "  # https://github.com/quarto-dev/quarto-cli/issues/7548\n",
    "  if fig_format == :pdf\n",
    "    CairoMakie.activate!(type = \"png\")\n",
    "  else\n",
    "    CairoMakie.activate!(type = string(fig_format))\n",
    "  end\n",
    "  CairoMakie.update_theme!(resolution=(fig_width, fig_height))\n",
    "catch e\n",
    "    # @warn \"CairoMakie init\" exception=(e, catch_backtrace())\n",
    "end\n",
    "  \n",
    "# Set run_path if specified\n",
    "try\n",
    "  run_path = raw\"/home/vituri/Documentos/GitHub/TDA_workshop_EBT2024\"\n",
    "  if !isempty(run_path)\n",
    "    cd(run_path)\n",
    "  end\n",
    "catch e\n",
    "  @warn \"Run path init:\" exception=(e, catch_backtrace())\n",
    "end\n",
    "\n",
    "\n",
    "# emulate old Pkg.installed beahvior, see\n",
    "# https://discourse.julialang.org/t/how-to-use-pkg-dependencies-instead-of-pkg-installed/36416/9\n",
    "import Pkg\n",
    "function isinstalled(pkg::String)\n",
    "  any(x -> x.name == pkg && x.is_direct_dep, values(Pkg.dependencies()))\n",
    "end\n",
    "\n",
    "# ojs_define\n",
    "if isinstalled(\"JSON\") && isinstalled(\"DataFrames\")\n",
    "  import JSON, DataFrames\n",
    "  global function ojs_define(; kwargs...)\n",
    "    convert(x) = x\n",
    "    convert(x::DataFrames.AbstractDataFrame) = Tables.rows(x)\n",
    "    content = Dict(\"contents\" => [Dict(\"name\" => k, \"value\" => convert(v)) for (k, v) in kwargs])\n",
    "    tag = \"<script type='ojs-define'>$(JSON.json(content))</script>\"\n",
    "    IJulia.display(MIME(\"text/html\"), tag)\n",
    "  end\n",
    "elseif isinstalled(\"JSON\")\n",
    "  import JSON\n",
    "  global function ojs_define(; kwargs...)\n",
    "    content = Dict(\"contents\" => [Dict(\"name\" => k, \"value\" => v) for (k, v) in kwargs])\n",
    "    tag = \"<script type='ojs-define'>$(JSON.json(content))</script>\"\n",
    "    IJulia.display(MIME(\"text/html\"), tag)\n",
    "  end\n",
    "else\n",
    "  global function ojs_define(; kwargs...)\n",
    "    @warn \"JSON package not available. Please install the JSON.jl package to use ojs_define.\"\n",
    "  end\n",
    "end\n",
    "\n",
    "\n",
    "# don't return kernel dependencies (b/c Revise should take care of dependencies)\n",
    "nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f092b0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m Meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangDataFramesExt\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTransducers → TransducersDataFramesExt\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mMeshes\n",
      "  3 dependencies successfully precompiled in 6 seconds. 101 already precompiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m MeshesMakieExt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMeshes → MeshesMakieExt\u001b[39m\n",
      "  1 dependency successfully precompiled in 5 seconds. 330 already precompiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GeoIO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLittleCMS_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibPQ_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBlosc_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mReadVTK\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibzip_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPROJ_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenJpeg_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibgeotiff_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNetCDF_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGeoJSON → GeoJSONMakieExt\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90meccodes_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDataScienceTraits → DataScienceTraitsMeshesExt\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGRIB\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGDAL_jll\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGeoTables\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGeoParquet\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGRIBDatasets\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNCDatasets\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGDAL\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGeoTables → GeoTablesMakieExt\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGslibIO\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArchGDAL\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mGeoIO\n",
      "  23 dependencies successfully precompiled in 41 seconds. 404 already precompiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m GLMakie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mMeshIO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mGLMakie\n",
      "  2 dependencies successfully precompiled in 33 seconds. 298 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "using Meshes, GeoIO\n",
    "import GLMakie as gl\n",
    "import DelimitedFiles\n",
    "using ProgressMeter\n",
    "\n",
    "# using Graphs, SimpleWeightedGraphs\n",
    "# using MetricSpaces, Ripserer, PersistenceDiagrams\n",
    "# using Chain\n",
    "\n",
    "# # functions\n",
    "# function reduz_obj(arquivo, n_points=1000)\n",
    "#     geotable = GeoIO.load(arquivo)\n",
    "\n",
    "#     X_total = geotable.vertices .|> coordinates .|> Vector |> EuclideanSpace\n",
    "\n",
    "#     ids = farthest_points_sample(X_total, n_points)\n",
    "#     X = X_total[ids]\n",
    "\n",
    "#     arquivo_novo = replace(arquivo, \".obj\" => \".csv\")\n",
    "#     DelimitedFiles.writedlm(arquivo_novo, stack(X)' |> Matrix, \",\")\n",
    "\n",
    "#     X\n",
    "# end\n",
    "\n",
    "# function meshes_to_csv(dir_path)\n",
    "#     for (root, dirs, files) ∈ collect(walkdir(dir_path))\n",
    "#         for file ∈ files\n",
    "#             if occursin(\".obj\", file)\n",
    "#                 arquivo = joinpath(root, file)\n",
    "#                 println(arquivo)\n",
    "#                 reduz_obj(arquivo)\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# read_mesh(arquivo) = GeoIO.load(arquivo).geometry\n",
    "\n",
    "# function mesh_to_graph(ms, X)\n",
    "#     g = SimpleWeightedGraph()\n",
    "#     n = length(X)\n",
    "#     add_vertices!(g, n)\n",
    "\n",
    "#     triangles = ms.topology.connec\n",
    "\n",
    "#     @showprogress desc = \"Adding vertices to graph...\" for t ∈ triangles\n",
    "#         v1, v2, v3 = t.indices\n",
    "#         add_edge!(g, v1, v2, dist_euclidean(X[v1], X[v2]))\n",
    "\n",
    "#         add_edge!(g, v1, v3, dist_euclidean(X[v1], X[v3]))\n",
    "\n",
    "#         add_edge!(g, v2, v3, dist_euclidean(X[v2], X[v3]))\n",
    "#     end\n",
    "\n",
    "#     g\n",
    "# end\n",
    "\n",
    "# mesh_to_metric_space(ms) = ms.vertices .|> coordinates .|> Vector |> EuclideanSpace\n",
    "\n",
    "# function geodesic_distance_from_graph(g, ids)\n",
    "#     n = length(ids)\n",
    "#     D = zeros(n, n)\n",
    "\n",
    "#     @showprogress desc = \"Calculating geodesic distance...\" Threads.@threads for (i, id) ∈ collect(enumerate(ids))\n",
    "#         dts = dijkstra_shortest_paths(g, id)\n",
    "#         D[i, :] = dts.dists[ids]\n",
    "#     end\n",
    "\n",
    "#     return D\n",
    "# end\n",
    "\n",
    "# plot_mesh(ms) = viz(ms)\n",
    "\n",
    "\n",
    "# # ----------------------\n",
    "# # script\n",
    "# ms = read_mesh(\"meshes/flamingo-poses/flam-01.obj\")\n",
    "# # ms = GeoIO.load(\"meshes/flamingo-poses/flam-01.obj\")\n",
    "\n",
    "# plot_mesh(ms)\n",
    "\n",
    "\n",
    "# # componentes\n",
    "# function barcode_from_mesh(ms, n_points=1000)\n",
    "#     X_total = mesh_to_metric_space(ms)\n",
    "\n",
    "#     g = mesh_to_graph(ms, X_total)\n",
    "\n",
    "#     componentes_g = connected_components(g)\n",
    "#     ids_maior_componente = componentes_g[findmax(length, componentes_g)[2]]\n",
    "\n",
    "#     X_total = X_total[ids_maior_componente]\n",
    "\n",
    "#     g = g[ids_maior_componente]\n",
    "\n",
    "\n",
    "#     fts_sample = farthest_points_sample(X_total, n_points)\n",
    "#     X = X_total[fts_sample]\n",
    "#     D = geodesic_distance_from_graph(g, fts_sample)\n",
    "\n",
    "#     # force simmetry on X\n",
    "#     for i ∈ 1:n_points\n",
    "#         for j ∈ i:n_points\n",
    "#             D[i, j] = D[j, i]\n",
    "#         end\n",
    "#     end\n",
    "\n",
    "#     max_dist = maximum(D)\n",
    "#     D = D ./ max_dist\n",
    "\n",
    "#     pd = ripserer(D, dim_max = 2, verbose=true, sparse = true, threshold = 0.9)\n",
    "\n",
    "#     pd, D, X, g\n",
    "\n",
    "# end\n",
    "\n",
    "# pd, D, X, g = barcode_from_mesh(ms, 300)\n",
    "\n",
    "# exc = mapslices(sum, D, dims=2) |> vec\n",
    "\n",
    "# gl.scatter(X, color=exc)\n",
    "\n",
    "# import Plots\n",
    "# Plots.plot(pd)\n",
    "# barcode(pd)\n",
    "\n",
    "# # calcula pds\n",
    "\n",
    "# function list_files(path=\"\", pattern=\"\")\n",
    "#     files =\n",
    "#         @chain begin\n",
    "#             map(walkdir(path)) do (root, dirs, files)\n",
    "#                 joinpath.(root, files)\n",
    "#             end\n",
    "#             reduce(vcat, _)\n",
    "#             filter(x -> occursin(pattern, x), _)\n",
    "#         end\n",
    "\n",
    "#     files\n",
    "# end\n",
    "\n",
    "# arquivos = list_files(\"meshes/\", \".obj\")\n",
    "\n",
    "# arquivos = arquivos[1:5:80]\n",
    "\n",
    "# analises =\n",
    "#     @showprogress desc=\"lendo arquivo...\" map(arquivos) do file\n",
    "#         ms = read_mesh(file)\n",
    "#         pd, D, X, g = barcode_from_mesh(ms)\n",
    "#     end\n",
    "\n",
    "# analises[1]\n",
    "# barcode(analises[1][1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# arquivos = [\n",
    "#     \"meshes/flamingo-poses/flam-01.obj\"\n",
    "#     ,\"meshes/elephant-poses/elephant-01.obj\"\n",
    "# ]\n",
    "\n",
    "# analises = map(arquivos) do f\n",
    "#     ms = read_mesh(f)\n",
    "#     barcode_from_mesh(ms, 350)\n",
    "# end\n",
    "\n",
    "# pd, D, X, g = analises[1]\n",
    "# exc = mapslices(sum, D, dims=2) |> vec\n",
    "# gl.scatter(X, color=exc)\n",
    "# barcode(pd)\n",
    "\n",
    "# pd, D, X, g = analises[2]\n",
    "# exc = mapslices(sum, D, dims=2) |> vec\n",
    "# gl.scatter(X, color=exc)\n",
    "# barcode(pd)\n",
    "\n",
    "# Bottleneck()(analises[1][1][2:3], analises[2][1][2:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}